{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>A template for turning Jupyter notebooks and markdown files into a website.</p> <p>Steps to use this template:</p> <ul> <li>Click the Use this template green button on this GitHub repo and fill in the details to create a repo under your account.</li> <li>Clone the newly created repo to your computer and open it using a Text Editor (e.g., Visual Studio Code).</li> <li>Use the Text Editor to search <code>notebook-share</code> and replace it with your repo name.</li> <li>Add/remove dependencies in <code>requirements.txt</code> if need.</li> <li>Add folders (e.g., <code>chapter_01</code>) and files (e.g., <code>intro.ipynb</code>, <code>index.md</code>) to the <code>docs</code> folder.</li> <li>Open <code>mkdocs.yml</code> and make several changes, including <code>site_name</code>, <code>site_url</code>, <code>repo_url</code>, and <code>nav</code>. If you don't want the notebooks to be executed when building the website, set <code>execute: False</code> under <code>plugins</code>.</li> <li>Customize the issue template (<code>.github/ISSUE_TEMPLATE/config.yml</code>) if needed.</li> <li>Commit the changes using Git and push changes to GitHub.</li> <li>Enable GitHub Pages through GitHub Settings - Pages.</li> <li>Check out the website at https://username.github.io/repo-name.</li> </ul>"},{"location":"geemap/landcover_app/","title":"Exploring the interactive visualisation capabilities of Google Earth Engine (GEE) for geospatial datasets","text":"In\u00a0[\u00a0]: Copied! <pre>import geemap\nimport ee\n\n# if on google colab\n# ee.Authenticate()\n# ee.Initialize(project='test1-420603')\n\nimport pandas as pd\nfrom io import StringIO\n\ndef rgb2hex(r,g,b):\n    return \"#{:02x}{:02x}{:02x}\".format(r,g,b)\n\ndef hex2rgb(hexcode):\n    return tuple(map(ord,hexcode[1:].decode('hex')))\n\n\n# legends = geemap.builtin_legends\n# for legend in legends:\n#     print(legend)\n</pre> import geemap import ee  # if on google colab # ee.Authenticate() # ee.Initialize(project='test1-420603')  import pandas as pd from io import StringIO  def rgb2hex(r,g,b):     return \"#{:02x}{:02x}{:02x}\".format(r,g,b)  def hex2rgb(hexcode):     return tuple(map(ord,hexcode[1:].decode('hex')))   # legends = geemap.builtin_legends # for legend in legends: #     print(legend)  In\u00a0[\u00a0]: Copied! <pre>Map = geemap.Map(center=[-40,175], zoom=6)#, toolbar_ctrl=True, layer_ctrl=True)\nMap\n</pre> Map = geemap.Map(center=[-40,175], zoom=6)#, toolbar_ctrl=True, layer_ctrl=True) Map In\u00a0[\u00a0]: Copied! <pre># Add worldcover 10m\n# worldcover2020_name = 'ESA WorldCover 2020 (10m)'\n# worldcover2020 = ee.ImageCollection(\"ESA/WorldCover/v100\").first()\n# Map.addLayer(worldcover2020, {}, worldcover2020_name)\n\n\nworldcover2021 = ee.ImageCollection(\"ESA/WorldCover/v200\").first()\n# Map.addLayer(worldcover2021, {}, 'ESA WorldCover 2021 (10m)')\n\n# Map.add_legend(title=\"ESA WorldCover (10m)\", builtin_legend=\"ESA_WorldCover\")\n</pre>  # Add worldcover 10m # worldcover2020_name = 'ESA WorldCover 2020 (10m)' # worldcover2020 = ee.ImageCollection(\"ESA/WorldCover/v100\").first() # Map.addLayer(worldcover2020, {}, worldcover2020_name)   worldcover2021 = ee.ImageCollection(\"ESA/WorldCover/v200\").first() # Map.addLayer(worldcover2021, {}, 'ESA WorldCover 2021 (10m)')  # Map.add_legend(title=\"ESA WorldCover (10m)\", builtin_legend=\"ESA_WorldCover\")  In\u00a0[\u00a0]: Copied! <pre>globcover2009 = ee.Image('ESA/GLOBCOVER_L4_200901_200912_V2_3').select('landcover')\n\nlegend = pd.read_csv(StringIO(\"\"\"\nRed,Green,Blue,Class,Label\n170,240,240,11,11 Post-flood/irrigated croplands (3)\n255,255,100,14,14 Rainfed croplands (5)\n220,240,100,20,20 Mosaic cropland 50-70%/vegetation 20-50% (9)\n205,205,102,30,30 Mosaic cropland 50-70%/vegetation 20-50% (9)\n0,100,0,40,40 &gt;15% Evergreen broadleaf/semi-deciduous (11/13)\n0,160,0,50,50 &gt;40% Deciduous Broadleaf Forest (11)\n170,200,0,60,60 15-40% Deciduous Broadleaf Forest(11)\n0,60,0,70,70 &gt;40% Evergreen Needleleaf Forest (14)\n40,100,0,90,90 15-40% Needleleaf deciduous/evergreen (12/14)\n120,130,0,100,100 &gt;15% Broadleaf/NeedleLeaf (13/14)\n140,160,0,110,110 50-70% forest/shrubland 20-50% grassland (13)\n190,150,0,120,120 50-70% grassland 20-50% forest/shrubland (6)\n150,100,0,130,130 &gt;15% Shrubland (8)\n255,180,50,140,140 &gt;15% herbaceous vegetation (10)\n255,235,175,150,150 Sparsely (&lt;15%) Vegetated (19)\n0,120,90,160,160 Regularly flooded broadleaf (18)\n0,150,120,170,170 Permanently flooded broadleaf/shrubland (17)\n0,220,130,180,180 Regularly flooded grassland/woody vegetation (3/17)\n195,20,0,190,190 Artificial (1)\n255,245,215,200,200 Barren (19)\n0,70,200,210,210 Water Bodies (16)\n255,255,255,220,220 Snow or Ice (24)\n\"\"\"))\n\nlegend['Color'] = legend[['Red', 'Green', 'Blue']].apply(lambda x: rgb2hex(*x), axis=1)\n\nvis_param = {\n    \"min\": 11,\n    \"max\": 220,\n    \"palette\": list(legend['Color']),\n}\n\nlegend_dict = {}\nfor index, row in legend.iterrows():\n  legend_dict[row['Label']] = row['Color']\n\n\n# Map.addLayer(globcover2009, vis_param, globcover2009_name)\n# Map.add_legend(title='ESA Globcover 2009 (300 m)', legend_dict=legend_dict, position='bottomleft')\n</pre> globcover2009 = ee.Image('ESA/GLOBCOVER_L4_200901_200912_V2_3').select('landcover')  legend = pd.read_csv(StringIO(\"\"\" Red,Green,Blue,Class,Label 170,240,240,11,11 Post-flood/irrigated croplands (3) 255,255,100,14,14 Rainfed croplands (5) 220,240,100,20,20 Mosaic cropland 50-70%/vegetation 20-50% (9) 205,205,102,30,30 Mosaic cropland 50-70%/vegetation 20-50% (9) 0,100,0,40,40 &gt;15% Evergreen broadleaf/semi-deciduous (11/13) 0,160,0,50,50 &gt;40% Deciduous Broadleaf Forest (11) 170,200,0,60,60 15-40% Deciduous Broadleaf Forest(11) 0,60,0,70,70 &gt;40% Evergreen Needleleaf Forest (14) 40,100,0,90,90 15-40% Needleleaf deciduous/evergreen (12/14) 120,130,0,100,100 &gt;15% Broadleaf/NeedleLeaf (13/14) 140,160,0,110,110 50-70% forest/shrubland 20-50% grassland (13) 190,150,0,120,120 50-70% grassland 20-50% forest/shrubland (6) 150,100,0,130,130 &gt;15% Shrubland (8) 255,180,50,140,140 &gt;15% herbaceous vegetation (10) 255,235,175,150,150 Sparsely (&lt;15%) Vegetated (19) 0,120,90,160,160 Regularly flooded broadleaf (18) 0,150,120,170,170 Permanently flooded broadleaf/shrubland (17) 0,220,130,180,180 Regularly flooded grassland/woody vegetation (3/17) 195,20,0,190,190 Artificial (1) 255,245,215,200,200 Barren (19) 0,70,200,210,210 Water Bodies (16) 255,255,255,220,220 Snow or Ice (24) \"\"\"))  legend['Color'] = legend[['Red', 'Green', 'Blue']].apply(lambda x: rgb2hex(*x), axis=1)  vis_param = {     \"min\": 11,     \"max\": 220,     \"palette\": list(legend['Color']), }  legend_dict = {} for index, row in legend.iterrows():   legend_dict[row['Label']] = row['Color']   # Map.addLayer(globcover2009, vis_param, globcover2009_name) # Map.add_legend(title='ESA Globcover 2009 (300 m)', legend_dict=legend_dict, position='bottomleft')   In\u00a0[\u00a0]: Copied! <pre>left_layer = geemap.ee_tile_layer(globcover2009, vis_param, 'ESA Globcover 2009 (300 m)')\nright_layer = geemap.ee_tile_layer(worldcover2021, {}, 'ESA Worldcover 2021 (10 m)')\n\nMap.split_map(left_layer, right_layer)\n\nMap.add_legend(title='ESA Globcover 2009 (300 m)', legend_dict=legend_dict, position='bottomleft')\nMap.add_legend(title=\"ESA WorldCover 2021 (10 m)\", builtin_legend=\"ESA_WorldCover\", position='bottomright')\n</pre> left_layer = geemap.ee_tile_layer(globcover2009, vis_param, 'ESA Globcover 2009 (300 m)') right_layer = geemap.ee_tile_layer(worldcover2021, {}, 'ESA Worldcover 2021 (10 m)')  Map.split_map(left_layer, right_layer)  Map.add_legend(title='ESA Globcover 2009 (300 m)', legend_dict=legend_dict, position='bottomleft') Map.add_legend(title=\"ESA WorldCover 2021 (10 m)\", builtin_legend=\"ESA_WorldCover\", position='bottomright')"},{"location":"geemap/landcover_app/#exploring-the-interactive-visualisation-capabilities-of-google-earth-engine-gee-for-geospatial-datasets","title":"Exploring the interactive visualisation capabilities of Google Earth Engine (GEE) for geospatial datasets\u00b6","text":"<p>Based on work by https://github.com/opengeos/voila-geospatial/</p> <p>My app running in https://huggingface.co/spaces/rosatrancoso/voila-geospatial/blob/main/notebooks/landcover_app.ipynb</p> <p>To do: Resolve permissions</p> <p>This work explores the interactive visualization capabilities of Google Earth Engine (GEE) for high resolution global coverage geospatial datasets, namely the 10-meter resolution global land use dataset (WorldCover 2021)</p> <p>I tested whether it could render the 10-meter land use dataset (WorldCover) that QGIS was struggling with, and it could do so with ease. This is because GEE loads images from Cloud Optimized GeoTiffs (COGs) stored in Google Cloud.</p> <p>I used the GEE Python API and geemap, a Python package that allows users to analyze and visualize GEE datasets interactively, including within a Jupyter environment. I then used Voila to wrap my Jupyter Notebook and make it available as an app on HuggingFaces (following this book and this tutorial).</p> <p>I made this example landcover_app) where you can compare the SUPER high-resolution 10-meter land use dataset (Worldcover 2021; right side panel) with the current 300-meter land use dataset used by our WRFs (Globcover 2009; left side panel). The Jupyter Notebook runs on the fly, and the loading of the datasets is almost immediate. Additionally, the split panel functionality makes it simple to compare datasets, in this case, land use changes over time, from 2009 (left side) to 2021 (right side). The most notable example is the expansion of urban/built areas (both classes are red) in the last decade. The notebook code is available here.</p> <p>This research aligns with our ongoing work to update the geostatic datasets of WRF, specifically land use, albedo, leaf area index, and vegetation fraction, for a more accurate characterization of surface fluxes.</p>"},{"location":"hydrology/get_basin_reporoa/","title":"Get basin from near outlet coordinates","text":"In\u00a0[1]: Copied! <pre>from shapely.geometry import Polygon\nimport branca\nimport fiona\nimport folium\nimport geopandas as gpd\nimport numpy as np\nimport pandas as pd\n\ndef get_shapefile_rows(filename, irows):\n    ''' https://gis.stackexchange.com/questions/220023/only-read-specific-rows-of-a-shapefile-with-geopandas-fiona'''\n    irows = sorted(irows) # if the elements of the list    are not sorted\n    features = []\n    imin = min(irows)\n    imax = max(irows)+1\n    print('getting {} rows from {} to {}'.format(imax-imin+1, imin,imax))\n    with fiona.open(filename) as source:\n        for i, feature in enumerate(source[imin:imax]):\n            irow = i + imin\n            if irow in irows:\n                features += [feature]\n    return gpd.GeoDataFrame.from_features(features)\n\n\ndef get_upstream_ids (tbr, rid, maxiter=50):\n    '''\n        tbr: pandas table with reaches attributes\n        rid: HydroID of outlet reach\n    '''\n    reaches = [rid]\n    i = 0\n    newids = reaches\n    while i &lt; maxiter:\n        newids2 = []\n        for rid in newids:\n            # get upstream ids\n            newids2 += list(tbr[tbr['NextDownID'] == rid]['HydroID'])\n        print('iter {}: found {} upstream reaches.'.format(i,len(newids2)))\n        reaches += newids2\n        if len(newids) == 0:\n            i = maxiter + 1\n        else:\n            i = i + 1\n            newids = newids2\n        reaches.sort()\n    return reaches\n</pre>  from shapely.geometry import Polygon import branca import fiona import folium import geopandas as gpd import numpy as np import pandas as pd  def get_shapefile_rows(filename, irows):     ''' https://gis.stackexchange.com/questions/220023/only-read-specific-rows-of-a-shapefile-with-geopandas-fiona'''     irows = sorted(irows) # if the elements of the list    are not sorted     features = []     imin = min(irows)     imax = max(irows)+1     print('getting {} rows from {} to {}'.format(imax-imin+1, imin,imax))     with fiona.open(filename) as source:         for i, feature in enumerate(source[imin:imax]):             irow = i + imin             if irow in irows:                 features += [feature]     return gpd.GeoDataFrame.from_features(features)   def get_upstream_ids (tbr, rid, maxiter=50):     '''         tbr: pandas table with reaches attributes         rid: HydroID of outlet reach     '''     reaches = [rid]     i = 0     newids = reaches     while i &lt; maxiter:         newids2 = []         for rid in newids:             # get upstream ids             newids2 += list(tbr[tbr['NextDownID'] == rid]['HydroID'])         print('iter {}: found {} upstream reaches.'.format(i,len(newids2)))         reaches += newids2         if len(newids) == 0:             i = maxiter + 1         else:             i = i + 1             newids = newids2         reaches.sort()     return reaches  In\u00a0[2]: Copied! <pre>crs_wgs84 = 'epsg:4326'\ncrs_nz = 'epsg:2193'\n\nshpfile_rivers = 'data/River_Lines.shp'\nshpfile_wsheds = 'data/Watersheds.shp'\n\n## also need this to get full basin without reading entire shapefile\ncsvfile_rivers = 'data/River_Lines.csv'\ncsvfile_wsheds = 'data/Watersheds.csv'\n\n\n## output files\nbasin_name = 'Reporoa'\n\nfileout_html = 'basin_{}.html'.format(basin_name)\nfileout_rivers_json = '{}_rivers_wgs84.json'.format(basin_name)\nfileout_wsheds_json = '{}_watersheds_wgs84.json'.format(basin_name)\nfileout_outershed_json = '{}_outershed_wgs84.json'.format(basin_name)\n</pre> crs_wgs84 = 'epsg:4326' crs_nz = 'epsg:2193'  shpfile_rivers = 'data/River_Lines.shp' shpfile_wsheds = 'data/Watersheds.shp'  ## also need this to get full basin without reading entire shapefile csvfile_rivers = 'data/River_Lines.csv' csvfile_wsheds = 'data/Watersheds.csv'   ## output files basin_name = 'Reporoa'  fileout_html = 'basin_{}.html'.format(basin_name) fileout_rivers_json = '{}_rivers_wgs84.json'.format(basin_name) fileout_wsheds_json = '{}_watersheds_wgs84.json'.format(basin_name) fileout_outershed_json = '{}_outershed_wgs84.json'.format(basin_name)  In\u00a0[3]: Copied! <pre># Reporoa\ny0,x0 = -38.436619, 176.339975\nbufx=0.1\nbufy=0.1\nx1,x2 = x0-bufx/2, x0+bufx/2.\ny1,y2 = y0-bufy/2, y0+bufy/2.\nprint(x1,x2,y1,y2)\n#x1,x2,y1,y2 = 175,177,-39,-37\nbbox = gpd.GeoSeries(Polygon(((x1, y1), (x2,y1), (x2,y2), (x1,y2))))\nbbox.crs = crs_wgs84\nprint(bbox)\n\nbbox_nz = bbox.to_crs(crs_nz)\nprint(bbox_nz)\n</pre> # Reporoa y0,x0 = -38.436619, 176.339975 bufx=0.1 bufy=0.1 x1,x2 = x0-bufx/2, x0+bufx/2. y1,y2 = y0-bufy/2, y0+bufy/2. print(x1,x2,y1,y2) #x1,x2,y1,y2 = 175,177,-39,-37 bbox = gpd.GeoSeries(Polygon(((x1, y1), (x2,y1), (x2,y2), (x1,y2)))) bbox.crs = crs_wgs84 print(bbox)  bbox_nz = bbox.to_crs(crs_nz) print(bbox_nz) <pre>176.289975 176.38997500000002 -38.486619 -38.386619\n0    POLYGON ((176.28998 -38.48662, 176.38998 -38.4...\ndtype: geometry\n0    POLYGON ((1886967.769 5735060.81, 1895692.538 ...\ndtype: geometry\n</pre> In\u00a0[4]: Copied! <pre>%%time\n# 4s\nrivers_nz = gpd.read_file(shpfile_rivers, bbox=bbox_nz)\nprint(len(rivers_nz))\n</pre> %%time # 4s rivers_nz = gpd.read_file(shpfile_rivers, bbox=bbox_nz) print(len(rivers_nz)) <pre>257\nCPU times: user 166 ms, sys: 235 ms, total: 401 ms\nWall time: 707 ms\n</pre> In\u00a0[5]: Copied! <pre>outlet = rivers_nz[rivers_nz['CUM_AREA'] == rivers_nz['CUM_AREA'].max()]\noutlet\n</pre> outlet = rivers_nz[rivers_nz['CUM_AREA'] == rivers_nz['CUM_AREA'].max()] outlet Out[5]: OBJECTID_1 HydroID NextDownID CATAREA CUM_AREA nzsegment Enabled LENGTHDOWN Headwater Hydseq ... headw_dist segslpmean LID reachtype FROM_NODE TO_NODE Shape_Leng FLOWDIR GlobalID geometry 242 119246 119223 118992 295668.106341 4.162465e+09 3119272 1 290959.754971 0 184705 ... 163268 0.008472 0 0 124044 123807 1113.01299 1 c85adc9a-c5f3-4c12-bca8-fa7c88bf4b81 LINESTRING (1887546.652 5734893.334, 1887516.5... <p>1 rows \u00d7 30 columns</p> In\u00a0[6]: Copied! <pre>rivers_nz.crs = crs_nz\nrivers = rivers_nz.to_crs(crs_wgs84)\nrivers['geoid'] = rivers.index.astype(str)\n\nfig = folium.Figure(width=800, height=400)\nm = folium.Map(location=[x0,y0]).add_to(fig)\n\nfolium.Marker([y0,x0], tooltip=basin_name, popup=basin_name).add_to(m)\n\nfolium.Choropleth(bbox,\n                 fill_color='transparent').add_to(m)\n\n\nlayer_name = 'HydroID'\n\nfolium.GeoJson(rivers,\n               name=layer_name,\n               style_function=lambda feature: dict(color='blue', weight=1),\n               tooltip=folium.GeoJsonTooltip(fields=[layer_name], aliases=[layer_name], labels=True, sticky=False)\n              ).add_to(m)\n\n\n\noutlet = rivers[rivers['CUM_AREA'] == rivers['CUM_AREA'].max()]\nprint(outlet[layer_name])\nfolium.GeoJson(outlet,\n               name=layer_name,\n               style_function=lambda feature: dict(color='yellow', weight=2),\n               tooltip=folium.GeoJsonTooltip(fields=[layer_name], aliases=[layer_name], labels=True, sticky=False)\n              ).add_to(m)\n\n\noutlet = rivers[rivers['HydroID'] == 118993]\nfolium.GeoJson(outlet,\n               name=layer_name,\n               style_function=lambda feature: dict(color='red', weight=2),\n               tooltip=folium.GeoJsonTooltip(fields=[layer_name], aliases=[layer_name], labels=True, sticky=False)\n              ).add_to(m)\n\nm.fit_bounds(m.get_bounds(),max_zoom=14)\nm\n</pre> rivers_nz.crs = crs_nz rivers = rivers_nz.to_crs(crs_wgs84) rivers['geoid'] = rivers.index.astype(str)  fig = folium.Figure(width=800, height=400) m = folium.Map(location=[x0,y0]).add_to(fig)  folium.Marker([y0,x0], tooltip=basin_name, popup=basin_name).add_to(m)  folium.Choropleth(bbox,                  fill_color='transparent').add_to(m)   layer_name = 'HydroID'  folium.GeoJson(rivers,                name=layer_name,                style_function=lambda feature: dict(color='blue', weight=1),                tooltip=folium.GeoJsonTooltip(fields=[layer_name], aliases=[layer_name], labels=True, sticky=False)               ).add_to(m)    outlet = rivers[rivers['CUM_AREA'] == rivers['CUM_AREA'].max()] print(outlet[layer_name]) folium.GeoJson(outlet,                name=layer_name,                style_function=lambda feature: dict(color='yellow', weight=2),                tooltip=folium.GeoJsonTooltip(fields=[layer_name], aliases=[layer_name], labels=True, sticky=False)               ).add_to(m)   outlet = rivers[rivers['HydroID'] == 118993] folium.GeoJson(outlet,                name=layer_name,                style_function=lambda feature: dict(color='red', weight=2),                tooltip=folium.GeoJsonTooltip(fields=[layer_name], aliases=[layer_name], labels=True, sticky=False)               ).add_to(m)  m.fit_bounds(m.get_bounds(),max_zoom=14) m  <pre>242    119223\nName: HydroID, dtype: int64\n</pre> Out[6]: In\u00a0[7]: Copied! <pre>outlet  # 118993\n</pre> outlet  # 118993 Out[7]: OBJECTID_1 HydroID NextDownID CATAREA CUM_AREA nzsegment Enabled LENGTHDOWN Headwater Hydseq ... segslpmean LID reachtype FROM_NODE TO_NODE Shape_Leng FLOWDIR GlobalID geometry geoid 237 119016 118993 118992 562488.727169 341314336.0 3119079 1 290959.754971 0 116915 ... 0.014783 0 0 123607 123807 880.107246 1 7cc2003a-48d0-44fc-a35d-23b62ad6ff01 LINESTRING (176.29474 -38.4834, 176.29242 -38.... 237 <p>1 rows \u00d7 31 columns</p> In\u00a0[8]: Copied! <pre>%%time\n\n# Read all watersheds and rivers but from csv file otherwise too slow\n# 6.51s\n\n# needs this to get upstream full basin\ntbw = pd.read_csv(csvfile_wsheds)\nprint(tbw.shape)\ntbw.head(2)\n\ntbr = pd.read_csv(csvfile_rivers)\nprint(tbr.shape)\ntbr.head(2)\n</pre> %%time  # Read all watersheds and rivers but from csv file otherwise too slow # 6.51s  # needs this to get upstream full basin tbw = pd.read_csv(csvfile_wsheds) print(tbw.shape) tbw.head(2)  tbr = pd.read_csv(csvfile_rivers) print(tbr.shape) tbr.head(2) <pre>(593517, 8)\n(593517, 31)\nCPU times: user 1.92 s, sys: 792 ms, total: 2.71 s\nWall time: 3.02 s\n</pre> Out[8]: OBJECTID_1 OBJECTID HydroID NextDownID CATAREA CUM_AREA nzsegment Enabled LENGTHDOWN Headwater ... headw_dist segslpmean LID reachtype FROM_NODE TO_NODE Shape_Leng FLOWDIR Shape__Length GlobalID 0 1 1 1 9 218553.786394 218553.80 1000005 1 1801.260253 1 ... 0 8.388180 0 0 1 2 213.567866 1 213.567866 6304120b-27ba-41db-8dca-1197d7e05ea1 1 2 2 2 9 455995.848576 455995.81 1000003 1 1801.260253 1 ... 0 7.678527 0 0 3 2 581.789877 1 581.789877 8d81048e-c368-4dc6-86b1-672ebb2c9f0c <p>2 rows \u00d7 31 columns</p> In\u00a0[9]: Copied! <pre>%%time\nreaches = get_upstream_ids(tbr, rid=int(outlet['HydroID']), maxiter=100)\nprint(len(reaches))\n</pre> %%time reaches = get_upstream_ids(tbr, rid=int(outlet['HydroID']), maxiter=100) print(len(reaches)) <pre>iter 0: found 2 upstream reaches.\niter 1: found 2 upstream reaches.\niter 2: found 2 upstream reaches.\niter 3: found 2 upstream reaches.\niter 4: found 2 upstream reaches.\niter 5: found 2 upstream reaches.\niter 6: found 4 upstream reaches.\niter 7: found 4 upstream reaches.\niter 8: found 4 upstream reaches.\niter 9: found 6 upstream reaches.\niter 10: found 6 upstream reaches.\niter 11: found 6 upstream reaches.\niter 12: found 8 upstream reaches.\niter 13: found 10 upstream reaches.\niter 14: found 10 upstream reaches.\niter 15: found 6 upstream reaches.\niter 16: found 12 upstream reaches.\niter 17: found 12 upstream reaches.\niter 18: found 14 upstream reaches.\niter 19: found 14 upstream reaches.\niter 20: found 18 upstream reaches.\niter 21: found 16 upstream reaches.\niter 22: found 22 upstream reaches.\niter 23: found 20 upstream reaches.\niter 24: found 18 upstream reaches.\niter 25: found 16 upstream reaches.\niter 26: found 20 upstream reaches.\niter 27: found 18 upstream reaches.\niter 28: found 14 upstream reaches.\niter 29: found 14 upstream reaches.\niter 30: found 12 upstream reaches.\niter 31: found 16 upstream reaches.\niter 32: found 12 upstream reaches.\niter 33: found 16 upstream reaches.\niter 34: found 20 upstream reaches.\niter 35: found 26 upstream reaches.\niter 36: found 20 upstream reaches.\n</pre> <pre>&lt;timed exec&gt;:1: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n</pre> <pre>iter 37: found 18 upstream reaches.\niter 38: found 20 upstream reaches.\niter 39: found 22 upstream reaches.\niter 40: found 24 upstream reaches.\niter 41: found 24 upstream reaches.\niter 42: found 18 upstream reaches.\niter 43: found 17 upstream reaches.\niter 44: found 16 upstream reaches.\niter 45: found 14 upstream reaches.\niter 46: found 14 upstream reaches.\niter 47: found 10 upstream reaches.\niter 48: found 12 upstream reaches.\niter 49: found 8 upstream reaches.\niter 50: found 12 upstream reaches.\niter 51: found 10 upstream reaches.\niter 52: found 6 upstream reaches.\niter 53: found 8 upstream reaches.\niter 54: found 8 upstream reaches.\niter 55: found 7 upstream reaches.\niter 56: found 2 upstream reaches.\niter 57: found 2 upstream reaches.\niter 58: found 2 upstream reaches.\niter 59: found 0 upstream reaches.\niter 60: found 0 upstream reaches.\n701\nCPU times: user 333 ms, sys: 631 \u03bcs, total: 334 ms\nWall time: 331 ms\n</pre> In\u00a0[10]: Copied! <pre>irows1 = [tbr[tbr['HydroID'] == rid].index[0] for rid in reaches]\nirows2 = [tbw[tbw['HydroID'] == rid].index[0] for rid in reaches]\n</pre> irows1 = [tbr[tbr['HydroID'] == rid].index[0] for rid in reaches] irows2 = [tbw[tbw['HydroID'] == rid].index[0] for rid in reaches] In\u00a0[11]: Copied! <pre>%%time\ndfr = get_shapefile_rows(shpfile_rivers, irows1)\nprint(dfr.shape)\ndfr.head(2)\n</pre> %%time dfr = get_shapefile_rows(shpfile_rivers, irows1) print(dfr.shape) dfr.head(2) <pre>getting 17283 rows from 101711 to 118993\n(701, 30)\nCPU times: user 783 ms, sys: 20.4 ms, total: 803 ms\nWall time: 800 ms\n</pre> Out[11]: geometry OBJECTID_1 HydroID NextDownID CATAREA CUM_AREA nzsegment Enabled LENGTHDOWN Headwater ... nzreach_re headw_dist segslpmean LID reachtype FROM_NODE TO_NODE Shape_Leng FLOWDIR GlobalID 0 LINESTRING (1892548.747 5757627.634, 1892593.7... 101733 101712 101998 982613.943736 982613.88 3101348 1 324554.756283 1 ... 3030789 0 2.251327 0 0 106499 106500 1167.502712 1 592d7dc7-0928-4d7c-b3e0-389c1ecb1cbe 1 LINESTRING (1892699.926 5756787.134, 1892805.0... 101757 101736 101998 480487.744369 480487.81 3102006 1 324554.756283 1 ... 3031057 0 3.943834 0 0 106524 106500 412.618596 1 5803fe51-b3f9-4ef4-9fd8-5154a39b26d7 <p>2 rows \u00d7 30 columns</p> In\u00a0[12]: Copied! <pre>%%time\ndfw = get_shapefile_rows(shpfile_wsheds, irows2)\nprint(dfw.shape)\ndfw.head(2)\n</pre> %%time dfw = get_shapefile_rows(shpfile_wsheds, irows2) print(dfw.shape) dfw.head(2) <pre>getting 17731 rows from 101323 to 119053\n(701, 6)\nCPU times: user 841 ms, sys: 160 ms, total: 1 s\nWall time: 1.01 s\n</pre> Out[12]: geometry HydroID nzsegment nzreach_re Area GlobalID 0 POLYGON ((1892788.395 5758063.294, 1892668.297... 101712 3101348 3030789 982613.943736 51677ddf-9b0d-4098-8907-5869ab52d3f6 1 POLYGON ((1892430.136 5756441.512, 1892430.099... 101736 3102006 3031057 480487.744369 c16a4b88-ce6a-493e-8843-413e86858e05 In\u00a0[13]: Copied! <pre>dfw.crs = crs_nz\ndfr.crs = crs_nz\n\ndfw = dfw.to_crs(crs_wgs84)\ndfr = dfr.to_crs(crs_wgs84)\n\n# dfw['geoid'] = dfw.index.astype(str)\n# dfr['geoid'] = dfr.index.astype(str)\n</pre> dfw.crs = crs_nz dfr.crs = crs_nz  dfw = dfw.to_crs(crs_wgs84) dfr = dfr.to_crs(crs_wgs84)  # dfw['geoid'] = dfw.index.astype(str) # dfr['geoid'] = dfr.index.astype(str) In\u00a0[14]: Copied! <pre># check if we are reading correctly\nr1 = np.sort(reaches)\nr2 = np.sort(dfr['HydroID'].values)\nr3 = np.sort(dfw['HydroID'].values)\nprint(np.all(r2 == r1))\nprint(np.all(r3 == r1))\n</pre> # check if we are reading correctly r1 = np.sort(reaches) r2 = np.sort(dfr['HydroID'].values) r3 = np.sort(dfw['HydroID'].values) print(np.all(r2 == r1)) print(np.all(r3 == r1)) <pre>True\nTrue\n</pre> In\u00a0[15]: Copied! <pre># copy some arguments from rivers to watershed for plotting\ndfw.set_index('HydroID', inplace=True)\ndfr.set_index('HydroID', inplace=True)\n\ndfw.loc[reaches, 'CUM_AREA'] = dfr.loc[reaches, 'CUM_AREA']\ndfw.loc[reaches, 'headw_dist'] = dfr.loc[reaches, 'headw_dist']\n\ndfw.reset_index(inplace=True)\ndfr.reset_index(inplace=True)\n</pre> # copy some arguments from rivers to watershed for plotting dfw.set_index('HydroID', inplace=True) dfr.set_index('HydroID', inplace=True)  dfw.loc[reaches, 'CUM_AREA'] = dfr.loc[reaches, 'CUM_AREA'] dfw.loc[reaches, 'headw_dist'] = dfr.loc[reaches, 'headw_dist']  dfw.reset_index(inplace=True) dfr.reset_index(inplace=True) In\u00a0[16]: Copied! <pre>%%time\ndfouter = gpd.GeoSeries(dfw.unary_union)\ndfouter.crs = crs_wgs84\nprint(type(dfw), type(dfouter))\n</pre> %%time dfouter = gpd.GeoSeries(dfw.unary_union) dfouter.crs = crs_wgs84 print(type(dfw), type(dfouter)) <pre>&lt;timed exec&gt;:1: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n</pre> <pre>&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt; &lt;class 'geopandas.geoseries.GeoSeries'&gt;\nCPU times: user 234 ms, sys: 756 \u03bcs, total: 235 ms\nWall time: 231 ms\n</pre> In\u00a0[17]: Copied! <pre>dfw['CUM_AREA_KM2'] = dfw['CUM_AREA']/1e6\nprint(dfw['CUM_AREA_KM2'].min(), dfw['CUM_AREA_KM2'].max())\n</pre> dfw['CUM_AREA_KM2'] = dfw['CUM_AREA']/1e6 print(dfw['CUM_AREA_KM2'].min(), dfw['CUM_AREA_KM2'].max()) <pre>0.076633 341.314336\n</pre> In\u00a0[18]: Copied! <pre>colorscale = branca.colormap.linear.YlOrRd_06.scale(0,400)\nprint(colorscale(0.5))\ncolorscale\n</pre> colorscale = branca.colormap.linear.YlOrRd_06.scale(0,400) print(colorscale(0.5)) colorscale <pre>#ffffb2ff\n</pre> Out[18]: 066.7133.3200.0266.7333.3400 In\u00a0[19]: Copied! <pre>layer_name = 'CUM_AREA_KM2'\ndfw.__geo_interface__['features'][0]['properties'][layer_name]\n</pre> layer_name = 'CUM_AREA_KM2' dfw.__geo_interface__['features'][0]['properties'][layer_name] Out[19]: <pre>0.98261388</pre> In\u00a0[20]: Copied! <pre>fig = folium.Figure(width=1200, height=600)\nm = folium.Map(location=[x0,y0]).add_to(fig)\nfolium.Marker([y0,x0], tooltip=basin_name, popup=basin_name).add_to(m)\n\nfolium.Choropleth(bbox, fill_color='transparent', name='bbox').add_to(m)\n\nfolium.Choropleth(dfouter, fill_color='transparent', name='full basin').add_to(m)\n\nfolium.Choropleth(dfr, key_on='feature.id', line_color='blue', name='river').add_to(m)\n\nfolium.GeoJson(dfw,\n               name=layer_name,\n               style_function=lambda feature: {\n                   'fillColor': colorscale(feature['properties'][layer_name]),\n                   'color': 'transparent',\n                   'fillOpacity': 0.4,\n               },\n              tooltip=folium.GeoJsonTooltip(fields=[layer_name],\n                                            aliases=[layer_name],\n                                            labels=True,\n                                            sticky=False)\n              ).add_to(m)\n\ncolorscale.caption = layer_name\ncolorscale.add_to(m)\n\nfolium.LayerControl().add_to(m)\nm.fit_bounds(m.get_bounds(),max_zoom=12)\nprint(fileout_html)\nm.save(fileout_html)\nm\n</pre> fig = folium.Figure(width=1200, height=600) m = folium.Map(location=[x0,y0]).add_to(fig) folium.Marker([y0,x0], tooltip=basin_name, popup=basin_name).add_to(m)  folium.Choropleth(bbox, fill_color='transparent', name='bbox').add_to(m)  folium.Choropleth(dfouter, fill_color='transparent', name='full basin').add_to(m)  folium.Choropleth(dfr, key_on='feature.id', line_color='blue', name='river').add_to(m)  folium.GeoJson(dfw,                name=layer_name,                style_function=lambda feature: {                    'fillColor': colorscale(feature['properties'][layer_name]),                    'color': 'transparent',                    'fillOpacity': 0.4,                },               tooltip=folium.GeoJsonTooltip(fields=[layer_name],                                             aliases=[layer_name],                                             labels=True,                                             sticky=False)               ).add_to(m)  colorscale.caption = layer_name colorscale.add_to(m)  folium.LayerControl().add_to(m) m.fit_bounds(m.get_bounds(),max_zoom=12) print(fileout_html) m.save(fileout_html) m <pre>basin_Reporoa.html\n</pre> Out[20]: In\u00a0[21]: Copied! <pre>print('Saving {}'.format(fileout_rivers_json))\ndfr.to_file(fileout_rivers_json, driver=\"GeoJSON\")\n\nprint('Saving {}'.format(fileout_wsheds_json))\ndfw.to_file(fileout_wsheds_json, driver=\"GeoJSON\")\n\nprint('Saving {}'.format(fileout_outershed_json))\ndfouter.to_file(fileout_outershed_json, driver=\"GeoJSON\")\n</pre>  print('Saving {}'.format(fileout_rivers_json)) dfr.to_file(fileout_rivers_json, driver=\"GeoJSON\")  print('Saving {}'.format(fileout_wsheds_json)) dfw.to_file(fileout_wsheds_json, driver=\"GeoJSON\")  print('Saving {}'.format(fileout_outershed_json)) dfouter.to_file(fileout_outershed_json, driver=\"GeoJSON\")  <pre>Saving Reporoa_rivers_wgs84.json\nSaving Reporoa_watersheds_wgs84.json\nSaving Reporoa_outershed_wgs84.json\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"hydrology/get_basin_reporoa/#get-basin-from-near-outlet-coordinates","title":"Get basin from near outlet coordinates\u00b6","text":""},{"location":"hydrology/get_basin_reporoa/#dataset","title":"Dataset\u00b6","text":"<p>Rivers and Watersheds from River Environment Classification (REC2) New Zealand</p> <p>Source: https://data-niwa.opendata.arcgis.com/datasets/river-environment-classification-web-map-rec2-v5</p> <p>Description: This is a Feature Layer Representation of the River Environment Classification (REC2) Version 5, June 2019 - a database of catchment spatial attributes - summarised for every segment in NZ network of rivers. [Rivers as lines and catchments polygons.]</p> <p>Note: Download both shapefile and csv table.</p>"},{"location":"hydrology/get_basin_reporoa/#search-for-max-drainage-area-within-bbox-outlet","title":"Search for max drainage area within bbox (\"outlet\")\u00b6","text":""},{"location":"hydrology/get_basin_reporoa/#get-upstream-basin-of-chosen-outlet","title":"Get upstream basin of chosen outlet\u00b6","text":""},{"location":"hydrology/get_basin_reporoa/#plot-folium","title":"Plot folium\u00b6","text":""},{"location":"hydrology/get_basin_reporoa/#save-output-geojson-files","title":"Save output geojson files\u00b6","text":""},{"location":"leafmap/02_basemaps/","title":"02_basemaps","text":"In\u00a0[4]: Copied! <pre>import leafmap.foliumap as leafmap\n</pre> import leafmap.foliumap as leafmap In\u00a0[5]: Copied! <pre>m = leafmap.Map()\nm\n</pre> m = leafmap.Map() m Out[5]: In\u00a0[6]: Copied! <pre>m = leafmap.Map()\nm.add_basemap('HYBRID')\nm\n</pre> m = leafmap.Map() m.add_basemap('HYBRID') m Out[6]: In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"leafmap/02_basemaps/#02_basemaps","title":"02_basemaps\u00b6","text":""},{"location":"leafmap/03_heatmap/","title":"03_heatmap","text":"In\u00a0[1]: Copied! <pre>import leafmap.foliumap as leafmap\n</pre> import leafmap.foliumap as leafmap In\u00a0[2]: Copied! <pre>filepath = \"https://raw.githubusercontent.com/giswqs/leafmap/master/examples/data/us_cities.csv\"\n</pre> filepath = \"https://raw.githubusercontent.com/giswqs/leafmap/master/examples/data/us_cities.csv\" In\u00a0[3]: Copied! <pre>m = leafmap.Map()\nm.add_heatmap(\n    filepath,\n    latitude=\"latitude\",\n    longitude='longitude',\n    value=\"pop_max\",\n    name=\"Heat map\",\n    radius=20,\n)\nm\n</pre> m = leafmap.Map() m.add_heatmap(     filepath,     latitude=\"latitude\",     longitude='longitude',     value=\"pop_max\",     name=\"Heat map\",     radius=20, ) m Out[3]:"},{"location":"leafmap/03_heatmap/#03_heatmap","title":"03_heatmap\u00b6","text":""},{"location":"leafmap/04_wmslayer_colorbar/","title":"04_wmslayer with colorbar","text":"In\u00a0[4]: Copied! <pre>import leafmap.foliumap as leafmap\n</pre> import leafmap.foliumap as leafmap In\u00a0[5]: Copied! <pre>Map = leafmap.Map()\n\nurl = \"https://elevation.nationalmap.gov/arcgis/services/3DEPElevation/ImageServer/WMSServer?\"\nMap.add_wms_layer(\n    url,\n    layers=\"3DEPElevation:Hillshade Elevation Tinted\",\n    name=\"USGS 3DEP Elevation\",\n    format=\"image/png\",\n    transparent=True,\n)\n</pre> Map = leafmap.Map()  url = \"https://elevation.nationalmap.gov/arcgis/services/3DEPElevation/ImageServer/WMSServer?\" Map.add_wms_layer(     url,     layers=\"3DEPElevation:Hillshade Elevation Tinted\",     name=\"USGS 3DEP Elevation\",     format=\"image/png\",     transparent=True, ) In\u00a0[6]: Copied! <pre>colors = ['006633', 'E5FFCC', '662A00', 'D8D8D8', 'F5F5F5']\nvmin = 0\nvmax = 4000\n\nMap.add_colorbar(colors=colors, vmin=vmin, vmax=vmax)\n\nMap\n</pre> colors = ['006633', 'E5FFCC', '662A00', 'D8D8D8', 'F5F5F5'] vmin = 0 vmax = 4000  Map.add_colorbar(colors=colors, vmin=vmin, vmax=vmax)  Map Out[6]:"},{"location":"leafmap/04_wmslayer_colorbar/#04_wmslayer-with-colorbar","title":"04_wmslayer with colorbar\u00b6","text":""},{"location":"leafmap/05_load_raster/","title":"05_load_raster","text":"In\u00a0[1]: Copied! <pre>import os\nimport leafmap.leafmap as leafmap\n</pre> import os import leafmap.leafmap as leafmap In\u00a0[2]: Copied! <pre>landsat = \"landsat.tif\"\ndem = \"dem.tif\"\n</pre> landsat = \"landsat.tif\" dem = \"dem.tif\" In\u00a0[3]: Copied! <pre>url1 = \"https://open.gishub.org/data/raster/landsat7.tif\"\nurl2 = \"https://open.gishub.org/data/raster/srtm90.tif\"\nsatellite = leafmap.download_file(url1, landsat)\ndem = leafmap.download_file(url2, dem)\n</pre> url1 = \"https://open.gishub.org/data/raster/landsat7.tif\" url2 = \"https://open.gishub.org/data/raster/srtm90.tif\" satellite = leafmap.download_file(url1, landsat) dem = leafmap.download_file(url2, dem) <pre>landsat.tif already exists. Skip downloading. Set overwrite=True to overwrite.\ndem.tif already exists. Skip downloading. Set overwrite=True to overwrite.\n</pre> In\u00a0[4]: Copied! <pre>! gdalinfo landsat.tif\n</pre> ! gdalinfo landsat.tif <pre>Driver: GTiff/GeoTIFF\nFiles: landsat.tif\nSize is 2181, 1917\nCoordinate System is:\nPROJCRS[\"WGS 84 / Pseudo-Mercator\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            MEMBER[\"World Geodetic System 1984 (G2296)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"Popular Visualisation Pseudo-Mercator\",\n        METHOD[\"Popular Visualisation Pseudo Mercator\",\n            ID[\"EPSG\",1024]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"False easting\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"easting (X)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"northing (Y)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Web mapping and visualisation.\"],\n        AREA[\"World between 85.06\u00b0S and 85.06\u00b0N.\"],\n        BBOX[-85.06,-180,85.06,180]],\n    ID[\"EPSG\",3857]]\nData axis to CRS axis mapping: 1,2\nOrigin = (-13651650.000000000000000,4576290.000000000000000)\nPixel Size = (30.000000000000000,-30.000000000000000)\nMetadata:\n  TIFFTAG_XRESOLUTION=1\n  TIFFTAG_YRESOLUTION=1\n  TIFFTAG_RESOLUTIONUNIT=1 (unitless)\n  OVR_RESAMPLING_ALG=NEAREST\n  AREA_OR_POINT=Area\nImage Structure Metadata:\n  LAYOUT=COG\n  COMPRESSION=DEFLATE\n  INTERLEAVE=PIXEL\nCorner Coordinates:\nUpper Left  (-13651650.000, 4576290.000) (122d38' 5.49\"W, 37d58'40.08\"N)\nLower Left  (-13651650.000, 4518780.000) (122d38' 5.49\"W, 37d34'10.00\"N)\nUpper Right (-13586220.000, 4576290.000) (122d 2'49.53\"W, 37d58'40.08\"N)\nLower Right (-13586220.000, 4518780.000) (122d 2'49.53\"W, 37d34'10.00\"N)\nCenter      (-13618935.000, 4547535.000) (122d20'27.51\"W, 37d46'26.05\"N)\nBand 1 Block=512x512 Type=Byte, ColorInterp=Red\n  NoData Value=0\n  Overviews: 1091x959, 546x480\nBand 2 Block=512x512 Type=Byte, ColorInterp=Green\n  NoData Value=0\n  Overviews: 1091x959, 546x480\nBand 3 Block=512x512 Type=Byte, ColorInterp=Blue\n  NoData Value=0\n  Overviews: 1091x959, 546x480\n</pre> In\u00a0[5]: Copied! <pre>m = leafmap.Map()\nm.add_raster(dem, colormap=\"terrain\", layer_name=\"DEM\")\nm.add_raster(landsat, bands=[1, 2, 3], layer_name=\"Landsat\") \n# m.add_raster(landsat, layer_name=\"Landsat\")\nm\n</pre> m = leafmap.Map() m.add_raster(dem, colormap=\"terrain\", layer_name=\"DEM\") m.add_raster(landsat, bands=[1, 2, 3], layer_name=\"Landsat\")  # m.add_raster(landsat, layer_name=\"Landsat\") m Out[5]: <pre>Map(center=[37.7736215, -122.34097449999999], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom\u2026</pre> In\u00a0[8]: Copied! <pre>! ncdump -h ../qva/qva_det_Ruapehu_202501081200.nc\n</pre> ! ncdump -h ../qva/qva_det_Ruapehu_202501081200.nc  <pre>netcdf qva_det_Ruapehu_202501081200 {\ndimensions:\n\ttime = UNLIMITED ; // (24 currently)\n\tlatitude = 361 ;\n\tlongitude = 441 ;\n\tlevels = 12 ;\nvariables:\n\tfloat latitude(latitude) ;\n\t\tlatitude:_FillValue = NaNf ;\n\t\tlatitude:long_name = \"latitude degrees north from the equator\" ;\n\t\tlatitude:units = \"degrees_north\" ;\n\t\tlatitude:point_spacing = \"even\" ;\n\tfloat longitude(longitude) ;\n\t\tlongitude:_FillValue = NaNf ;\n\t\tlongitude:long_name = \"longitude degrees east from the greenwich meridian\" ;\n\t\tlongitude:units = \"degrees_east\" ;\n\t\tlongitude:point_spacing = \"even\" ;\n\tdouble levels(levels) ;\n\t\tlevels:_FillValue = NaN ;\n\t\tlevels:long_name = \"Top of flight level layer\" ;\n\t\tlevels:units = \"feet\" ;\n\t\tlevels:axis = \"Z\" ;\n\t\tlevels:positive = \"up\" ;\n\tint64 time(time) ;\n\t\ttime:axis = \"T\" ;\n\t\ttime:long_name = \"time\" ;\n\t\ttime:units = \"hours since 2025-01-08T13:00:00\" ;\n\t\ttime:calendar = \"proleptic_gregorian\" ;\n\tfloat concentration(time, levels, latitude, longitude) ;\n\t\tconcentration:_FillValue = NaNf ;\n\t\tconcentration:long_name = \"Quantitative volcanic ash concentration from deterministic forecast\" ;\n\t\tconcentration:units = \"mg/m3\" ;\n\n// global attributes:\n\t\t:title = \"HYSPLIT Model Concentration Output\" ;\n\t\t:Conventions = \"CF-1.5\" ;\n\t\t:volcano_name = \"Ruapehu\" ;\n\t\t:eruption_lon_degrees = 175.57f ;\n\t\t:eruption_lat_degrees = -39.28f ;\n\t\t:eruption_vent_meters_msl = 2797.f ;\n\t\t:eruption_height_meters_msl = 12500.f ;\n\t\t:eruption_mass_eruption_rate_kgs = 87500. ;\n\t\t:eruption_start_time = \"2025-01-08T12:00:00\" ;\n\t\t:eruption_duration_s = 3600. ;\n}\n</pre> In\u00a0[36]: Copied! <pre>ds = leafmap.read_netcdf('../qva/qva_det_Ruapehu_202501081200.nc')\nds.rio.write_crs(\"EPSG:4326\", inplace=True)\n\nda = ds['concentration'].isel(time=2, levels=7)\nda = da.where(da &gt; 1e-6)\n\nda.plot()\n</pre> ds = leafmap.read_netcdf('../qva/qva_det_Ruapehu_202501081200.nc') ds.rio.write_crs(\"EPSG:4326\", inplace=True)  da = ds['concentration'].isel(time=2, levels=7) da = da.where(da &gt; 1e-6)  da.plot()    Out[36]: <pre>&lt;matplotlib.collections.QuadMesh at 0x706ccb8bdd10&gt;</pre> In\u00a0[37]: Copied! <pre>m = leafmap.Map()\nm.add_raster(da, layer_name=\"QVA\")\nm\n</pre> m = leafmap.Map() m.add_raster(da, layer_name=\"QVA\") m Out[37]: <pre>Map(center=[-39.279999000000004, 175.570007], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom\u2026</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"leafmap/05_load_raster/#05_load_raster","title":"05_load_raster\u00b6","text":"<p>Following  https://leafmap.org/notebooks/05_load_raster/</p> <p>Uses the ipyleaflet plotting backend. The folium plotting backend does not support the <code>add_raster</code> function.</p> <pre><code>conda create -n leafmap -c conda-forge leafmap xarray_leaflet localtileserver netcdf4\nconda activate leafmap\n</code></pre>"},{"location":"leafmap/05_load_raster/#load-tif-files-from-the-example","title":"load tif files from the example\u00b6","text":"<p>Download sample raster datasets</p> <p>More datasets can be downloaded from https://viewer.nationalmap.gov/basic/</p>"},{"location":"leafmap/05_load_raster/#load-a-netcdf-file","title":"load a netcdf file\u00b6","text":"<p>To be reviewed..</p>"},{"location":"miscellaneous/plot_cartopy_img_tiles_examples/","title":"Plot cartopy img_tiles","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport cartopy.crs as ccrs\nfrom cartopy.io import img_tiles\n\n\nextent = [172,179,-42,-34] # North island\nprint(f'width, height = ({extent[1]-extent[0]}, {extent[3]-extent[2]}) deg')\nzoom = 7\n\nextent = [-80,-50,-50,-10] # South America\nprint(f'width, height = ({extent[1]-extent[0]}, {extent[3]-extent[2]}) deg')\nzoom = 4\n\n\n# NOTE: zoom specifications should be selected based on extent:\n# -- 2     = coarse image, select for worldwide or continental scales\n# -- 4-6   = medium coarseness, select for countries and larger states\n# -- 6-10  = medium fineness, select for smaller states, regions, and cities\n# -- 10-12 = fine image, select for city boundaries and zip codes\n# -- 14+   = extremely fine image, select for roads, blocks, buildings\n# max 19\n</pre> import matplotlib.pyplot as plt import cartopy.crs as ccrs from cartopy.io import img_tiles   extent = [172,179,-42,-34] # North island print(f'width, height = ({extent[1]-extent[0]}, {extent[3]-extent[2]}) deg') zoom = 7  extent = [-80,-50,-50,-10] # South America print(f'width, height = ({extent[1]-extent[0]}, {extent[3]-extent[2]}) deg') zoom = 4   # NOTE: zoom specifications should be selected based on extent: # -- 2     = coarse image, select for worldwide or continental scales # -- 4-6   = medium coarseness, select for countries and larger states # -- 6-10  = medium fineness, select for smaller states, regions, and cities # -- 10-12 = fine image, select for city boundaries and zip codes # -- 14+   = extremely fine image, select for roads, blocks, buildings # max 19 <pre>width, height = (7, 8) deg\nwidth, height = (30, 40) deg\n</pre> In\u00a0[2]: Copied! <pre>fig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()})\nax.set_extent(extent)\nax.coastlines()\ngl = ax.gridlines(draw_labels=True)\ngl.top_labels = False\ngl.right_labels = False\n</pre> fig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()}) ax.set_extent(extent) ax.coastlines() gl = ax.gridlines(draw_labels=True) gl.top_labels = False gl.right_labels = False  In\u00a0[3]: Copied! <pre>fig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()})\nax.set_extent(extent)\nax.stock_img()\nax.coastlines()\ngl = ax.gridlines(draw_labels=True)\ngl.top_labels = False\ngl.right_labels = False\nax.set_title('stock_img')\n</pre> fig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()}) ax.set_extent(extent) ax.stock_img() ax.coastlines() gl = ax.gridlines(draw_labels=True) gl.top_labels = False gl.right_labels = False ax.set_title('stock_img') Out[3]: <pre>Text(0.5, 1.0, 'stock_img')</pre> In\u00a0[4]: Copied! <pre>fig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()})\nax.set_extent(extent)\nax.add_image(img_tiles.GoogleTiles(style='street'),zoom)\n# ax.coastlines()\ngl = ax.gridlines(draw_labels=True)\ngl.top_labels = False\ngl.right_labels = False\nax.set_title('GoogleTiles - street')\n</pre> fig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()}) ax.set_extent(extent) ax.add_image(img_tiles.GoogleTiles(style='street'),zoom) # ax.coastlines() gl = ax.gridlines(draw_labels=True) gl.top_labels = False gl.right_labels = False ax.set_title('GoogleTiles - street')  Out[4]: <pre>Text(0.5, 1.0, 'GoogleTiles - street')</pre> In\u00a0[5]: Copied! <pre>fig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()})\nax.set_extent(extent)\nax.add_image(img_tiles.GoogleTiles(style='satellite'),zoom)\n# ax.coastlines()\ngl = ax.gridlines(draw_labels=True)\ngl.top_labels = False\ngl.right_labels = False\nax.set_title('GoogleTiles  - satellite')\n</pre> fig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()}) ax.set_extent(extent) ax.add_image(img_tiles.GoogleTiles(style='satellite'),zoom) # ax.coastlines() gl = ax.gridlines(draw_labels=True) gl.top_labels = False gl.right_labels = False ax.set_title('GoogleTiles  - satellite')  Out[5]: <pre>Text(0.5, 1.0, 'GoogleTiles  - satellite')</pre> In\u00a0[6]: Copied! <pre># GoogleTiles terrain - all black!\n\nfig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()})\nax.set_extent(extent)\nax.add_image(img_tiles.GoogleTiles(style='terrain'),zoom)\n# ax.coastlines()\ngl = ax.gridlines(draw_labels=True)\ngl.top_labels = False\ngl.right_labels = False\nax.set_title('GoogleTiles - terrain')\n</pre> # GoogleTiles terrain - all black!  fig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()}) ax.set_extent(extent) ax.add_image(img_tiles.GoogleTiles(style='terrain'),zoom) # ax.coastlines() gl = ax.gridlines(draw_labels=True) gl.top_labels = False gl.right_labels = False ax.set_title('GoogleTiles - terrain')  Out[6]: <pre>Text(0.5, 1.0, 'GoogleTiles - terrain')</pre> In\u00a0[7]: Copied! <pre>fig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()})\nax.set_extent(extent)\nax.add_image(img_tiles.OSM(),zoom)\n# ax.coastlines()\ngl = ax.gridlines(draw_labels=True)\ngl.top_labels = False\ngl.right_labels = False\nax.set_title('OSM')\n</pre> fig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()}) ax.set_extent(extent) ax.add_image(img_tiles.OSM(),zoom) # ax.coastlines() gl = ax.gridlines(draw_labels=True) gl.top_labels = False gl.right_labels = False ax.set_title('OSM') Out[7]: <pre>Text(0.5, 1.0, 'OSM')</pre> In\u00a0[8]: Copied! <pre>#https://stackoverflow.com/questions/77248120/stamen-terrain-map-not-working-in-cartopy\n\ndef image_spoof(self, tile):\n\n    import io\n    from urllib.request import urlopen, Request\n    from PIL import Image\n\n    url = self._image_url(tile) # get the url of the street map API\n    req = Request(url) # start request\n    req.add_header('User-agent','Anaconda 3')\n    fh = urlopen(req)\n    im_data = io.BytesIO(fh.read())\n    fh.close()\n    img = Image.open(im_data)\n    img = img.convert(self.desired_tile_form) # set image format\n    return img, self.tileextent(tile), 'lower' # reformat for cartopy\n\nimg_tiles.OSM.get_image = image_spoof # reformat web request for street map spoofing\ntile_image = img_tiles.OSM() # spoofed, downloaded street map\n\nfig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()})\nax.set_extent(extent)\nax.add_image(tile_image,zoom)\n# ax.coastlines()\ngl = ax.gridlines(draw_labels=True)\ngl.top_labels = False\ngl.right_labels = False\nax.set_title('spoofed OSM')\n</pre> #https://stackoverflow.com/questions/77248120/stamen-terrain-map-not-working-in-cartopy  def image_spoof(self, tile):      import io     from urllib.request import urlopen, Request     from PIL import Image      url = self._image_url(tile) # get the url of the street map API     req = Request(url) # start request     req.add_header('User-agent','Anaconda 3')     fh = urlopen(req)     im_data = io.BytesIO(fh.read())     fh.close()     img = Image.open(im_data)     img = img.convert(self.desired_tile_form) # set image format     return img, self.tileextent(tile), 'lower' # reformat for cartopy  img_tiles.OSM.get_image = image_spoof # reformat web request for street map spoofing tile_image = img_tiles.OSM() # spoofed, downloaded street map  fig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()}) ax.set_extent(extent) ax.add_image(tile_image,zoom) # ax.coastlines() gl = ax.gridlines(draw_labels=True) gl.top_labels = False gl.right_labels = False ax.set_title('spoofed OSM')  Out[8]: <pre>Text(0.5, 1.0, 'spoofed OSM')</pre> In\u00a0[9]: Copied! <pre>img_tiles.QuadtreeTiles.get_image = image_spoof # reformat web request for street map spoofing\ntile_image = img_tiles.QuadtreeTiles() # spoofed, downloaded street map\n\nfig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()})\nax.set_extent(extent)\nax.add_image(tile_image,zoom)\n# ax.coastlines()\ngl = ax.gridlines(draw_labels=True)\ngl.top_labels = False\ngl.right_labels = False\nax.set_title('spoofed QuadtreeTiles')\n</pre> img_tiles.QuadtreeTiles.get_image = image_spoof # reformat web request for street map spoofing tile_image = img_tiles.QuadtreeTiles() # spoofed, downloaded street map  fig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()}) ax.set_extent(extent) ax.add_image(tile_image,zoom) # ax.coastlines() gl = ax.gridlines(draw_labels=True) gl.top_labels = False gl.right_labels = False ax.set_title('spoofed QuadtreeTiles') Out[9]: <pre>Text(0.5, 1.0, 'spoofed QuadtreeTiles')</pre> In\u00a0[10]: Copied! <pre>img_tiles.StadiaMapsTiles.get_image = image_spoof # reformat web request for street map spoofing\ntile_image = img_tiles.StadiaMapsTiles(style='alidade_smooth', apikey='3f2c1505-df0e-4ac6-940c-83febd5cd7c5') # spoofed, downloaded street map\n\nfig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()})\nax.set_extent(extent)\nax.add_image(tile_image,zoom)\n# ax.coastlines()\ngl = ax.gridlines(draw_labels=True)\ngl.top_labels = False\ngl.right_labels = False\nax.set_title('spoofed StadiaMapsTiles - alidade_smooth')\n</pre> img_tiles.StadiaMapsTiles.get_image = image_spoof # reformat web request for street map spoofing tile_image = img_tiles.StadiaMapsTiles(style='alidade_smooth', apikey='3f2c1505-df0e-4ac6-940c-83febd5cd7c5') # spoofed, downloaded street map  fig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()}) ax.set_extent(extent) ax.add_image(tile_image,zoom) # ax.coastlines() gl = ax.gridlines(draw_labels=True) gl.top_labels = False gl.right_labels = False ax.set_title('spoofed StadiaMapsTiles - alidade_smooth')  Out[10]: <pre>Text(0.5, 1.0, 'spoofed StadiaMapsTiles - alidade_smooth')</pre> In\u00a0[11]: Copied! <pre>img_tiles.StadiaMapsTiles.get_image = image_spoof #\ntile_image = img_tiles.StadiaMapsTiles(style='stamen_terrain', apikey='3f2c1505-df0e-4ac6-940c-83febd5cd7c5') # spoofed, downloaded street map\n\nfig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()})\nax.set_extent(extent)\nax.add_image(tile_image,zoom)\n# ax.coastlines()\ngl = ax.gridlines(draw_labels=True)\ngl.top_labels = False\ngl.right_labels = False\nax.set_title('spoofed StadiaMapsTiles - stamen_terrain')\n</pre> img_tiles.StadiaMapsTiles.get_image = image_spoof # tile_image = img_tiles.StadiaMapsTiles(style='stamen_terrain', apikey='3f2c1505-df0e-4ac6-940c-83febd5cd7c5') # spoofed, downloaded street map  fig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()}) ax.set_extent(extent) ax.add_image(tile_image,zoom) # ax.coastlines() gl = ax.gridlines(draw_labels=True) gl.top_labels = False gl.right_labels = False ax.set_title('spoofed StadiaMapsTiles - stamen_terrain') Out[11]: <pre>Text(0.5, 1.0, 'spoofed StadiaMapsTiles - stamen_terrain')</pre> In\u00a0[12]: Copied! <pre>img_tiles.StadiaMapsTiles.get_image = image_spoof #\ntile_image = img_tiles.StadiaMapsTiles(style='osm_bright', apikey='3f2c1505-df0e-4ac6-940c-83febd5cd7c5') # spoofed, downloaded street map\n\nfig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()})\nax.set_extent(extent)\nax.add_image(tile_image,zoom)\n# ax.coastlines()\ngl = ax.gridlines(draw_labels=True)\ngl.top_labels = False\ngl.right_labels = False\nax.set_title('spoofed StadiaMapsTiles - osm_bright')\n</pre> img_tiles.StadiaMapsTiles.get_image = image_spoof # tile_image = img_tiles.StadiaMapsTiles(style='osm_bright', apikey='3f2c1505-df0e-4ac6-940c-83febd5cd7c5') # spoofed, downloaded street map  fig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()}) ax.set_extent(extent) ax.add_image(tile_image,zoom) # ax.coastlines() gl = ax.gridlines(draw_labels=True) gl.top_labels = False gl.right_labels = False ax.set_title('spoofed StadiaMapsTiles - osm_bright') Out[12]: <pre>Text(0.5, 1.0, 'spoofed StadiaMapsTiles - osm_bright')</pre> In\u00a0[13]: Copied! <pre># or a full reference on the styles available please see\n# https://docs.stadiamaps.com/themes/.\n</pre> # or a full reference on the styles available please see # https://docs.stadiamaps.com/themes/."},{"location":"miscellaneous/plot_cartopy_img_tiles_examples/#plot-cartopy-img_tiles","title":"Plot cartopy img_tiles\u00b6","text":""},{"location":"miscellaneous/plot_cartopy_img_tiles_examples/#simple","title":"Simple\u00b6","text":"<p>no img_tiles</p>"},{"location":"miscellaneous/plot_cartopy_img_tiles_examples/#stock_img","title":"stock_img\u00b6","text":""},{"location":"miscellaneous/plot_cartopy_img_tiles_examples/#googletiles","title":"GoogleTiles\u00b6","text":""},{"location":"miscellaneous/plot_cartopy_img_tiles_examples/#street","title":"street\u00b6","text":""},{"location":"miscellaneous/plot_cartopy_img_tiles_examples/#satellite","title":"satellite\u00b6","text":""},{"location":"miscellaneous/plot_cartopy_img_tiles_examples/#terrain","title":"terrain\u00b6","text":"<p>all black..</p>"},{"location":"miscellaneous/plot_cartopy_img_tiles_examples/#osm","title":"OSM\u00b6","text":""},{"location":"miscellaneous/plot_cartopy_img_tiles_examples/#spoofed-osm","title":"spoofed OSM\u00b6","text":""},{"location":"miscellaneous/plot_cartopy_img_tiles_examples/#spoofed-quadtreetiles","title":"spoofed QuadtreeTiles\u00b6","text":""},{"location":"miscellaneous/plot_cartopy_img_tiles_examples/#spoofed-stadiamapstiles","title":"spoofed StadiaMapsTiles\u00b6","text":""},{"location":"miscellaneous/plot_cartopy_img_tiles_examples/#alidade_smooth","title":"alidade_smooth\u00b6","text":""},{"location":"miscellaneous/plot_cartopy_img_tiles_examples/#stamen_terrain","title":"stamen_terrain\u00b6","text":""},{"location":"miscellaneous/plot_cartopy_img_tiles_examples/#osm_bright","title":"osm_bright\u00b6","text":""},{"location":"miscellaneous/plot_cartopy_lambert_gridlines_dateline/","title":"Plot gridlines crossing dateline on Lambert projection","text":"In\u00a0[1]: Copied! <pre>import cartopy.crs as ccrs\nimport matplotlib.pyplot as plt\n</pre> import cartopy.crs as ccrs import matplotlib.pyplot as plt  In\u00a0[2]: Copied! <pre># Create a Lambert Conformal projection:\n# +proj=lcc +lat_0=-40.630005 +lon_0=173.08 +lat_1=-30 +lat_2=-60 +x_0=0 +y_0=0 +R=6370000 +nadgrids=@null +units=m +no_defs +type=crs'\nproj = ccrs.LambertConformal(central_longitude=173.08, central_latitude=-40.630005,\n                             false_easting=0, false_northing=0,\n                             standard_parallels=(-30, -60))\n\n# Draw a set of axes with coastlines:\nfig = plt.figure(figsize=(9, 9), frameon=True)\nax = fig.add_axes([0.08, 0.05, 0.8, 0.94], projection=proj)\nax.set_extent([160, 190, -50, -30], crs=ccrs.PlateCarree())\nax.coastlines(resolution='50m')\n\nax.gridlines(draw_labels=True, xlocs=[160, 165, 170, 175, 179.99999, -175, -170])#, ylocs=[-50, -45, -40, -35, -30])\n</pre> # Create a Lambert Conformal projection: # +proj=lcc +lat_0=-40.630005 +lon_0=173.08 +lat_1=-30 +lat_2=-60 +x_0=0 +y_0=0 +R=6370000 +nadgrids=@null +units=m +no_defs +type=crs' proj = ccrs.LambertConformal(central_longitude=173.08, central_latitude=-40.630005,                              false_easting=0, false_northing=0,                              standard_parallels=(-30, -60))  # Draw a set of axes with coastlines: fig = plt.figure(figsize=(9, 9), frameon=True) ax = fig.add_axes([0.08, 0.05, 0.8, 0.94], projection=proj) ax.set_extent([160, 190, -50, -30], crs=ccrs.PlateCarree()) ax.coastlines(resolution='50m')  ax.gridlines(draw_labels=True, xlocs=[160, 165, 170, 175, 179.99999, -175, -170])#, ylocs=[-50, -45, -40, -35, -30])  Out[2]: <pre>&lt;cartopy.mpl.gridliner.Gridliner at 0x7280039f38c0&gt;</pre> In\u00a0[3]: Copied! <pre># Create a Lambert Conformal projection:\n# +proj=lcc +lat_0=-40.630005 +lon_0=173.08 +lat_1=-30 +lat_2=-60 +x_0=0 +y_0=0 +R=6370000 +nadgrids=@null +units=m +no_defs +type=crs'\nproj = ccrs.LambertConformal(central_longitude=173.08, central_latitude=-40.630005,\n                             false_easting=0, false_northing=0,\n                             standard_parallels=(-30, -60))\n\n# Draw a set of axes with coastlines:\nfig = plt.figure(figsize=(9, 9), frameon=True)\nax = fig.add_axes([0.08, 0.05, 0.8, 0.94], projection=proj)\nax.set_extent([160, 190, -50, -30], crs=ccrs.PlateCarree())\nax.coastlines(resolution='50m')\n\ngl = ax.gridlines(draw_labels=True, x_inline=False, xlocs=[160, 165, 170, 175, 179.99999, -175, -170])#, ylocs=[-50, -45, -40, -35, -30])\ngl.xlabel_style = dict(rotation=0, ha='center') #{'size': 6, 'color': 'w', 'rotation': 0, 'ha':'right'}\ngl.right_labels = False\ngl.top_labels = False\n</pre> # Create a Lambert Conformal projection: # +proj=lcc +lat_0=-40.630005 +lon_0=173.08 +lat_1=-30 +lat_2=-60 +x_0=0 +y_0=0 +R=6370000 +nadgrids=@null +units=m +no_defs +type=crs' proj = ccrs.LambertConformal(central_longitude=173.08, central_latitude=-40.630005,                              false_easting=0, false_northing=0,                              standard_parallels=(-30, -60))  # Draw a set of axes with coastlines: fig = plt.figure(figsize=(9, 9), frameon=True) ax = fig.add_axes([0.08, 0.05, 0.8, 0.94], projection=proj) ax.set_extent([160, 190, -50, -30], crs=ccrs.PlateCarree()) ax.coastlines(resolution='50m')  gl = ax.gridlines(draw_labels=True, x_inline=False, xlocs=[160, 165, 170, 175, 179.99999, -175, -170])#, ylocs=[-50, -45, -40, -35, -30]) gl.xlabel_style = dict(rotation=0, ha='center') #{'size': 6, 'color': 'w', 'rotation': 0, 'ha':'right'} gl.right_labels = False gl.top_labels = False In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"miscellaneous/plot_cartopy_lambert_gridlines_dateline/#plot-gridlines-crossing-dateline-on-lambert-projection","title":"Plot gridlines crossing dateline on Lambert projection\u00b6","text":""},{"location":"miscellaneous/plot_coastlines/","title":"Compare coastlines","text":"In\u00a0[1]: Copied! <pre>import cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nimport matplotlib.pyplot as plt\nimport matplotlib.lines as mlines\n\nimport geopandas as gpd\nimport requests\nimport geojson\n</pre> import cartopy.crs as ccrs import cartopy.feature as cfeature import matplotlib.pyplot as plt import matplotlib.lines as mlines  import geopandas as gpd import requests import geojson  In\u00a0[2]: Copied! <pre>coastline_GSHSS = cfeature.GSHHSFeature(scale='full')  #scale = \u2018auto\u2019, \u2018coarse\u2019, \u2018low\u2019, \u2018intermediate\u2019, \u2018high', or \u2018full\u2019\n</pre> coastline_GSHSS = cfeature.GSHHSFeature(scale='full')  #scale = \u2018auto\u2019, \u2018coarse\u2019, \u2018low\u2019, \u2018intermediate\u2019, \u2018high', or \u2018full\u2019 In\u00a0[3]: Copied! <pre>#https://www.linz.govt.nz/guidance/data-service/linz-data-service-guide/web-services/wfs-filtering-attribute-or-feature\n\n\nurl = \"https://data.linz.govt.nz/services;key=2649806d1e794603a07a711a152f3ba5/wfs\"\n\nparams = dict(\n    service=\"WFS\",\n    request=\"GetFeature\",\n    typeName=\"layer-105085\",\n    outputFormat=\"json\",\n)\n\nr = requests.get(url, params=params)\nprint(r.url)\n\ndata = gpd.GeoDataFrame.from_features(geojson.loads(r.content), crs=\"EPSG:2193\")\ndata.to_crs(\"EPSG:4326\", inplace=True)\nprint(data.shape)\ndata.head()\n</pre> #https://www.linz.govt.nz/guidance/data-service/linz-data-service-guide/web-services/wfs-filtering-attribute-or-feature   url = \"https://data.linz.govt.nz/services;key=2649806d1e794603a07a711a152f3ba5/wfs\"  params = dict(     service=\"WFS\",     request=\"GetFeature\",     typeName=\"layer-105085\",     outputFormat=\"json\", )  r = requests.get(url, params=params) print(r.url)  data = gpd.GeoDataFrame.from_features(geojson.loads(r.content), crs=\"EPSG:2193\") data.to_crs(\"EPSG:4326\", inplace=True) print(data.shape) data.head() <pre>https://data.linz.govt.nz/services;key=2649806d1e794603a07a711a152f3ba5/wfs?service=WFS&amp;request=GetFeature&amp;typeName=layer-105085&amp;outputFormat=json\n(17840, 7)\n</pre> Out[3]: geometry id coast_category publish_date source scale length 0 MULTILINESTRING ((179.0614 -47.76398, 179.0611... 16876 None 2011 Topo Map Sheet BI01 25000 86 1 MULTILINESTRING ((179.06779 -47.76246, 179.067... 16878 None 2011 Topo Map Sheet BI01 25000 38 2 MULTILINESTRING ((-178.55677 -30.54441, -178.5... 17398 None 2011 Topo Map Sheet KI04 25000 45 3 MULTILINESTRING ((-177.8567 -29.24599, -177.85... 17344 steep coast 2011 Topo Map Sheet KI02ptKI01 25000 110 4 MULTILINESTRING ((179.03842 -47.76385, 179.038... 16405 None 2011 Topo Map Sheet BI01 25000 119 In\u00a0[4]: Copied! <pre>def plot_coastlines(window=[174, 176, -36, -38], clon=180, leg_loc='lower right', xlocs=None):\n\n    import matplotlib.pyplot as plt\n    import cartopy.crs as ccrs\n\n    fig, ax = plt.subplots(1,1, figsize=(10,8), subplot_kw={'projection': ccrs.PlateCarree(clon)})\n    ax.set_extent(window)\n\n    leg_handles = []\n\n    ax.coastlines('10m', color='red')\n    leg_handles += [mlines.Line2D([], [], color='red', label='Natural Earth')]\n\n    ax.add_feature(coastline_GSHSS, edgecolor='k',facecolor='none', lw=2)\n    leg_handles += [mlines.Line2D([], [], color='k', lw=2, label='GSHSS')]\n\n    data.plot(ax=ax, color='g', transform=ccrs.PlateCarree())\n    leg_handles += [mlines.Line2D([], [], color='g', label='LINZ coastline mean-high water')]\n\n    ax.legend(handles=leg_handles, loc=leg_loc)\n    gl = ax.gridlines(draw_labels=True, xlocs=xlocs)\n\n    return fig,ax\n\n#, xlocs=np.arange(160,190,5))\n</pre> def plot_coastlines(window=[174, 176, -36, -38], clon=180, leg_loc='lower right', xlocs=None):      import matplotlib.pyplot as plt     import cartopy.crs as ccrs      fig, ax = plt.subplots(1,1, figsize=(10,8), subplot_kw={'projection': ccrs.PlateCarree(clon)})     ax.set_extent(window)      leg_handles = []      ax.coastlines('10m', color='red')     leg_handles += [mlines.Line2D([], [], color='red', label='Natural Earth')]      ax.add_feature(coastline_GSHSS, edgecolor='k',facecolor='none', lw=2)     leg_handles += [mlines.Line2D([], [], color='k', lw=2, label='GSHSS')]      data.plot(ax=ax, color='g', transform=ccrs.PlateCarree())     leg_handles += [mlines.Line2D([], [], color='g', label='LINZ coastline mean-high water')]      ax.legend(handles=leg_handles, loc=leg_loc)     gl = ax.gridlines(draw_labels=True, xlocs=xlocs)      return fig,ax  #, xlocs=np.arange(160,190,5)) In\u00a0[5]: Copied! <pre>fig,ax = plot_coastlines(window=[174, 176, -36, -38], leg_loc='lower right')\n</pre> fig,ax = plot_coastlines(window=[174, 176, -36, -38], leg_loc='lower right') In\u00a0[6]: Copied! <pre>fig,ax = plot_coastlines(window=[176.5, 178.5, -40, -38.5], leg_loc='lower right')\n</pre> fig,ax = plot_coastlines(window=[176.5, 178.5, -40, -38.5], leg_loc='lower right') In\u00a0[7]: Copied! <pre>fig,ax = plot_coastlines(window=[172, 173.5, -44, -43], leg_loc='lower right')\n</pre> fig,ax = plot_coastlines(window=[172, 173.5, -44, -43], leg_loc='lower right') In\u00a0[8]: Copied! <pre>fig,ax = plot_coastlines(window=[166, 168.6, -47.5, -45], leg_loc='lower right')\n</pre> fig,ax = plot_coastlines(window=[166, 168.6, -47.5, -45], leg_loc='lower right')  In\u00a0[9]: Copied! <pre>fig,ax = plot_coastlines(window=[-9.6, -8.6, 38, 39.2], clon=0, leg_loc='lower right')\n</pre>  fig,ax = plot_coastlines(window=[-9.6, -8.6, 38, 39.2], clon=0, leg_loc='lower right') In\u00a0[10]: Copied! <pre>fig,ax = plot_coastlines(window=[-17.4, -16.4, 32.3, 33], clon=0, leg_loc='lower right')\n</pre> fig,ax = plot_coastlines(window=[-17.4, -16.4, 32.3, 33], clon=0, leg_loc='lower right') In\u00a0[11]: Copied! <pre>fig,ax = plot_coastlines(window=[-10, -8, 42, 44], clon=0, leg_loc='upper left')\n</pre> fig,ax = plot_coastlines(window=[-10, -8, 42, 44], clon=0, leg_loc='upper left') In\u00a0[12]: Copied! <pre>fig,ax = plot_coastlines(window=[4, 6, 59, 61], clon=0, leg_loc='lower left')\nax.plot(5.279957533657037,60.43858127037093, 'b*', ms=20)\nax.text(x=5.3,y=60.5, s='Bergen', color='blue', fontsize=20)\n</pre> fig,ax = plot_coastlines(window=[4, 6, 59, 61], clon=0, leg_loc='lower left') ax.plot(5.279957533657037,60.43858127037093, 'b*', ms=20) ax.text(x=5.3,y=60.5, s='Bergen', color='blue', fontsize=20)  Out[12]: <pre>Text(5.3, 60.5, 'Bergen')</pre>"},{"location":"miscellaneous/plot_coastlines/#compare-coastlines","title":"Compare coastlines\u00b6","text":"<ul> <li>Cartopy default - Natural-earth: https://www.naturalearthdata.com/</li> <li>GSHHS: https://www.ngdc.noaa.gov/mgg/shorelines/gshhs.html</li> <li>LINZ: https://data.linz.govt.nz/layer/105085-nz-coastline-mean-high-water/</li> </ul>"},{"location":"miscellaneous/plot_coastlines/#load-gshss-coastline","title":"Load GSHSS coastline\u00b6","text":""},{"location":"miscellaneous/plot_coastlines/#load-linz-coastline","title":"Load LINZ coastline\u00b6","text":""},{"location":"miscellaneous/plot_coastlines/#plots","title":"Plots\u00b6","text":""},{"location":"miscellaneous/plot_coastlines/#auckland","title":"Auckland\u00b6","text":""},{"location":"miscellaneous/plot_coastlines/#mahia","title":"Mahia\u00b6","text":""},{"location":"miscellaneous/plot_coastlines/#lyttelton","title":"Lyttelton\u00b6","text":""},{"location":"miscellaneous/plot_coastlines/#stewart-island","title":"Stewart Island\u00b6","text":""},{"location":"miscellaneous/plot_coastlines/#lisbon","title":"Lisbon\u00b6","text":""},{"location":"miscellaneous/plot_coastlines/#madeira-island","title":"Madeira Island\u00b6","text":""},{"location":"miscellaneous/plot_coastlines/#galicia","title":"Galicia\u00b6","text":""},{"location":"miscellaneous/plot_coastlines/#bergen-norway","title":"Bergen, Norway\u00b6","text":""},{"location":"miscellaneous/plot_colorbar_common/","title":"Plot common colorbar","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport xarray as xr\n</pre> import numpy as np import matplotlib.pyplot as plt import xarray as xr  In\u00a0[2]: Copied! <pre>x = np.arange(-5,5)\ny = np.arange(-6,4)\n\n\nfig, axs = plt.subplots(nrows=2, ncols=2)\nfor ax in axs.flat:\n    im = ax.pcolormesh(x,y, np.random.random((10,10)), vmin=0, vmax=1)\nfig.subplots_adjust(right=0.8)\n\n# [x0,y0,width,height]\ncbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\nfig.colorbar(im, cax=cbar_ax)\n</pre> x = np.arange(-5,5) y = np.arange(-6,4)   fig, axs = plt.subplots(nrows=2, ncols=2) for ax in axs.flat:     im = ax.pcolormesh(x,y, np.random.random((10,10)), vmin=0, vmax=1) fig.subplots_adjust(right=0.8)  # [x0,y0,width,height] cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7]) fig.colorbar(im, cax=cbar_ax) Out[2]: <pre>&lt;matplotlib.colorbar.Colorbar at 0x76bff32f5fd0&gt;</pre> In\u00a0[3]: Copied! <pre>fg= xr.concat([\n    ldasout_wrf['ACCPRCP'].isel(time=-1),\n    ldasout_sup['ACCPRCP'].isel(time=-1)],\n          dim='new_dim').plot(x='ix', y='iy', col='new_dim', cmap='gist_ncar')\n\ntitles = ['wrf', 'sup']\nfor i,ax in enumerate(fg.axs.flatten()):\n    ax.axis(zoom_land)\n    ax.set_title(titles[i])\n</pre> fg= xr.concat([     ldasout_wrf['ACCPRCP'].isel(time=-1),     ldasout_sup['ACCPRCP'].isel(time=-1)],           dim='new_dim').plot(x='ix', y='iy', col='new_dim', cmap='gist_ncar')  titles = ['wrf', 'sup'] for i,ax in enumerate(fg.axs.flatten()):     ax.axis(zoom_land)     ax.set_title(titles[i]) <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[3], line 2\n      1 fg= xr.concat([\n----&gt; 2     ldasout_wrf['ACCPRCP'].isel(time=-1),\n      3     ldasout_sup['ACCPRCP'].isel(time=-1)],\n      4           dim='new_dim').plot(x='ix', y='iy', col='new_dim', cmap='gist_ncar')\n      6 titles = ['wrf', 'sup']\n      7 for i,ax in enumerate(fg.axs.flatten()):\n\nNameError: name 'ldasout_wrf' is not defined</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"miscellaneous/plot_colorbar_common/#plot-common-colorbar","title":"Plot common colorbar\u00b6","text":""},{"location":"miscellaneous/plot_colorbar_common/#imshow","title":"imshow\u00b6","text":""},{"location":"miscellaneous/plot_colorbar_common/#xarray-data_vars","title":"xarray data_vars\u00b6","text":"<p>Not working , needs to read ldasout_wrf</p>"},{"location":"miscellaneous/plot_colorbar_discrete/","title":"Plot colorbar with discrete colors","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nfrom scipy.signal.windows import gaussian\n# import plotly.express as px\n</pre> import numpy as np import matplotlib as mpl import matplotlib.pyplot as plt  import numpy as np from scipy.signal.windows import gaussian # import plotly.express as px  In\u00a0[2]: Copied! <pre>vals = np.array([1,3,5,16,21])\niswater = 16\n\ndata = np.zeros((5,5))\nfor i, val in enumerate(vals):\n    data[i,:] = val\nplt.imshow(data)\nplt.colorbar()\n</pre>  vals = np.array([1,3,5,16,21]) iswater = 16  data = np.zeros((5,5)) for i, val in enumerate(vals):     data[i,:] = val plt.imshow(data) plt.colorbar()  Out[2]: <pre>&lt;matplotlib.colorbar.Colorbar at 0x75cf94cb8ad0&gt;</pre> In\u00a0[3]: Copied! <pre>print(vals)\n\nrgbs = mpl.cm.viridis(np.linspace(0,1,len(vals)+1))\nrgbs \n</pre> print(vals)  rgbs = mpl.cm.viridis(np.linspace(0,1,len(vals)+1)) rgbs  <pre>[ 1  3  5 16 21]\n</pre> Out[3]: <pre>array([[0.267004, 0.004874, 0.329415, 1.      ],\n       [0.253935, 0.265254, 0.529983, 1.      ],\n       [0.163625, 0.471133, 0.558148, 1.      ],\n       [0.134692, 0.658636, 0.517649, 1.      ],\n       [0.477504, 0.821444, 0.318195, 1.      ],\n       [0.993248, 0.906157, 0.143936, 1.      ]])</pre> In\u00a0[4]: Copied! <pre>print(mpl.colors.to_rgb('cyan')) \n\nidx = np.where(vals==iswater)[0][0]\nrgbs[idx,:] = list(mpl.colors.to_rgb('cyan')) + [1]\nprint(rgbs)\n\ncmap = mpl.colors.ListedColormap(rgbs[:-1]).with_extremes(over=rgbs[-1])\ncmap\n</pre> print(mpl.colors.to_rgb('cyan'))   idx = np.where(vals==iswater)[0][0] rgbs[idx,:] = list(mpl.colors.to_rgb('cyan')) + [1] print(rgbs)  cmap = mpl.colors.ListedColormap(rgbs[:-1]).with_extremes(over=rgbs[-1]) cmap <pre>(0.0, 1.0, 1.0)\n[[0.267004 0.004874 0.329415 1.      ]\n [0.253935 0.265254 0.529983 1.      ]\n [0.163625 0.471133 0.558148 1.      ]\n [0.       1.       1.       1.      ]\n [0.477504 0.821444 0.318195 1.      ]\n [0.993248 0.906157 0.143936 1.      ]]\n</pre> Out[4]: from_list  underbad over  In\u00a0[5]: Copied! <pre>norm = mpl.colors.BoundaryNorm(vals,cmap.N, extend='max')\nplt.imshow(data, cmap=cmap, norm=norm)\nplt.colorbar()\n</pre> norm = mpl.colors.BoundaryNorm(vals,cmap.N, extend='max') plt.imshow(data, cmap=cmap, norm=norm) plt.colorbar() Out[5]: <pre>&lt;matplotlib.colorbar.Colorbar at 0x75cf94b3d6d0&gt;</pre> In\u00a0[6]: Copied! <pre># Example from QVA\n\nthresholds = np.array([0.2,2,5,10])\nprint(thresholds)\n\ncolors_rgb= [\n    [160,210,255], # blue\n    [255,153,0], # orange\n    [255,40,0], # red\n    [170,0,170], # purple\n]\ncolors = [mpl.colors.to_hex(np.array(rgb)/255) for rgb in colors_rgb]\nprint(colors )\n\ncmap = mpl.colors.ListedColormap(colors)\ncmap \n</pre> # Example from QVA  thresholds = np.array([0.2,2,5,10]) print(thresholds)  colors_rgb= [     [160,210,255], # blue     [255,153,0], # orange     [255,40,0], # red     [170,0,170], # purple ] colors = [mpl.colors.to_hex(np.array(rgb)/255) for rgb in colors_rgb] print(colors )  cmap = mpl.colors.ListedColormap(colors) cmap   <pre>[ 0.2  2.   5.  10. ]\n['#a0d2ff', '#ff9900', '#ff2800', '#aa00aa']\n</pre> Out[6]: from_list  underbad over  In\u00a0[7]: Copied! <pre>N = 7   # kernel size\nk1d = gaussian(N, std=1).reshape(N, 1)\nkernel = np.outer(k1d, k1d)*11.\n\nplt.imshow(kernel)\nplt.colorbar()\n</pre>  N = 7   # kernel size k1d = gaussian(N, std=1).reshape(N, 1) kernel = np.outer(k1d, k1d)*11.  plt.imshow(kernel) plt.colorbar() Out[7]: <pre>&lt;matplotlib.colorbar.Colorbar at 0x75cf94a002d0&gt;</pre> <p>Mask below 0.1 with NaN</p> In\u00a0[8]: Copied! <pre># kernel_m1 = np.ma.masked_where(kernel&lt;0.1, kernel)\nkernel_m1 = np.where(kernel&lt;0.1, np.nan, kernel)\nprint(kernel_m1)\n\nplt.imshow(kernel_m1)\nplt.colorbar()\n</pre> # kernel_m1 = np.ma.masked_where(kernel&lt;0.1, kernel) kernel_m1 = np.where(kernel&lt;0.1, np.nan, kernel) print(kernel_m1)  plt.imshow(kernel_m1) plt.colorbar() <pre>[[        nan         nan         nan  0.12219896         nan         nan\n          nan]\n [        nan  0.20147203  0.90293498  1.48868812  0.90293498  0.20147203\n          nan]\n [        nan  0.90293498  4.04667385  6.67183726  4.04667385  0.90293498\n          nan]\n [ 0.12219896  1.48868812  6.67183726 11.          6.67183726  1.48868812\n   0.12219896]\n [        nan  0.90293498  4.04667385  6.67183726  4.04667385  0.90293498\n          nan]\n [        nan  0.20147203  0.90293498  1.48868812  0.90293498  0.20147203\n          nan]\n [        nan         nan         nan  0.12219896         nan         nan\n          nan]]\n</pre> Out[8]: <pre>&lt;matplotlib.colorbar.Colorbar at 0x75cf948bd450&gt;</pre> <p>Mask below 0.2 with NaN</p> In\u00a0[9]: Copied! <pre># kernel_m1 = np.ma.masked_where(kernel&lt;0.1, kernel)\nkernel_m2 = np.where(kernel&lt;thresholds[0], np.nan, kernel)\nprint(kernel_m2)\n\nplt.imshow(kernel_m2)\nplt.colorbar()\n</pre> # kernel_m1 = np.ma.masked_where(kernel&lt;0.1, kernel) kernel_m2 = np.where(kernel <pre>[[        nan         nan         nan         nan         nan         nan\n          nan]\n [        nan  0.20147203  0.90293498  1.48868812  0.90293498  0.20147203\n          nan]\n [        nan  0.90293498  4.04667385  6.67183726  4.04667385  0.90293498\n          nan]\n [        nan  1.48868812  6.67183726 11.          6.67183726  1.48868812\n          nan]\n [        nan  0.90293498  4.04667385  6.67183726  4.04667385  0.90293498\n          nan]\n [        nan  0.20147203  0.90293498  1.48868812  0.90293498  0.20147203\n          nan]\n [        nan         nan         nan         nan         nan         nan\n          nan]]\n</pre> Out[9]: <pre>&lt;matplotlib.colorbar.Colorbar at 0x75cf9477e5d0&gt;</pre> In\u00a0[10]: Copied! <pre>cmap = mpl.colors.ListedColormap(colors)\ncmap \n</pre> cmap = mpl.colors.ListedColormap(colors) cmap  Out[10]: from_list  underbad over  <p>without the <code>extend=max</code> option, the colorbar will not show the color for the pre-to-last value (red)</p> In\u00a0[11]: Copied! <pre>norm = mpl.colors.BoundaryNorm(thresholds,cmap.N)\n\nfig, ax = plt.subplots(figsize=(6, 1), layout='constrained')\nfig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap), \n             cax=ax, orientation='horizontal', label='extend neither')\n\nnorm = mpl.colors.BoundaryNorm(thresholds,cmap.N, extend='max')\n\nfig, ax = plt.subplots(figsize=(6, 1), layout='constrained')\nfig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap), \n             cax=ax, orientation='horizontal', label='extend max')\n</pre> norm = mpl.colors.BoundaryNorm(thresholds,cmap.N)  fig, ax = plt.subplots(figsize=(6, 1), layout='constrained') fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap),               cax=ax, orientation='horizontal', label='extend neither')  norm = mpl.colors.BoundaryNorm(thresholds,cmap.N, extend='max')  fig, ax = plt.subplots(figsize=(6, 1), layout='constrained') fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap),               cax=ax, orientation='horizontal', label='extend max')  Out[11]: <pre>&lt;matplotlib.colorbar.Colorbar at 0x75cf9467c2d0&gt;</pre> In\u00a0[12]: Copied! <pre>plt.imshow(kernel_m1, cmap=cmap, norm=norm)\nplt.colorbar()\n</pre> plt.imshow(kernel_m1, cmap=cmap, norm=norm) plt.colorbar() Out[12]: <pre>&lt;matplotlib.colorbar.Colorbar at 0x75cf946e9e50&gt;</pre> In\u00a0[13]: Copied! <pre>plt.imshow(kernel_m2, cmap=cmap, norm=norm)\nplt.colorbar()\n</pre> plt.imshow(kernel_m2, cmap=cmap, norm=norm) plt.colorbar() Out[13]: <pre>&lt;matplotlib.colorbar.Colorbar at 0x75cf945a9950&gt;</pre> In\u00a0[14]: Copied! <pre>kernel = np.outer(k1d, k1d)\nkernel_m2 = np.where(kernel&lt;thresholds[0], np.nan, kernel)\n\nfig, axs = plt.subplots(2,2, figsize=(10,10))\ni = 0\nfor x in [1,5,10,15]:\n    ax = axs.flatten()[i]\n    p1 = ax.pcolormesh(kernel_m2*x, cmap=cmap, norm=norm)\n    plt.colorbar(p1, ax=ax)\n    ax.set_title(f'x={x}')\n    i+=1\n</pre> kernel = np.outer(k1d, k1d) kernel_m2 = np.where(kernel In\u00a0[15]: Copied! <pre>kernel = np.outer(k1d, k1d)\nkernel_m1 = np.where(kernel&lt;0.1, np.nan, kernel)\n\nfig, axs = plt.subplots(2,2, figsize=(10,10))\ni = 0\nfor x in [1,5,10,15]:\n    ax = axs.flatten()[i]\n    p1 = ax.pcolormesh(kernel_m1*x, cmap=cmap, norm=norm)\n    plt.colorbar(p1, ax=ax)\n    ax.set_title(f'x={x}')\n    i+=1\n</pre> kernel = np.outer(k1d, k1d) kernel_m1 = np.where(kernel&lt;0.1, np.nan, kernel)  fig, axs = plt.subplots(2,2, figsize=(10,10)) i = 0 for x in [1,5,10,15]:     ax = axs.flatten()[i]     p1 = ax.pcolormesh(kernel_m1*x, cmap=cmap, norm=norm)     plt.colorbar(p1, ax=ax)     ax.set_title(f'x={x}')     i+=1"},{"location":"miscellaneous/plot_colorbar_discrete/#plot-colorbar-with-discrete-colors","title":"Plot colorbar with discrete colors\u00b6","text":""},{"location":"miscellaneous/plot_colorbar_discrete/#categorial-values","title":"Categorial values\u00b6","text":"<p>Usage: land use</p>"},{"location":"miscellaneous/plot_colorbar_discrete/#set-up-test-data","title":"Set up test data\u00b6","text":""},{"location":"miscellaneous/plot_colorbar_discrete/#continuous-field-with-categorical-thresholds","title":"Continuous field with categorical thresholds\u00b6","text":"<p>Usage: QVA, precipitation</p>"},{"location":"miscellaneous/plot_colorbar_discrete/#set-up-test-data","title":"Set up test data\u00b6","text":""},{"location":"miscellaneous/plot_colorbar_lognorm/","title":"Plot lognorm colorbar","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.colors\nimport matplotlib.cm\nimport xarray as xr\n\n# data = np.random.lognormal(sigma=6, size=(n,n))\n# plt.pcolormesh(data, norm=colors.LogNorm())\n# plt.colorbar()\n</pre> import numpy as np import matplotlib.pyplot as plt import matplotlib.colors import matplotlib.cm import xarray as xr  # data = np.random.lognormal(sigma=6, size=(n,n)) # plt.pcolormesh(data, norm=colors.LogNorm()) # plt.colorbar() In\u00a0[2]: Copied! <pre>vmin1 = 1.e-4\nvmax1 = 1.e4\nlev_exp1 = np.arange(np.log10(vmin1), np.log10(vmax1).max() + 1)\nprint(lev_exp1)\nlevs1 = np.power(10, lev_exp1)\nprint(levs1)\n\nlevs2 = levs1[1:-1]\nprint(levs2)\n</pre> vmin1 = 1.e-4 vmax1 = 1.e4 lev_exp1 = np.arange(np.log10(vmin1), np.log10(vmax1).max() + 1) print(lev_exp1) levs1 = np.power(10, lev_exp1) print(levs1)  levs2 = levs1[1:-1] print(levs2) <pre>[-4. -3. -2. -1.  0.  1.  2.  3.  4.]\n[1.e-04 1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02 1.e+03 1.e+04]\n[1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02 1.e+03]\n</pre> In\u00a0[3]: Copied! <pre>n = len(levs1)*10\nprint(n)\n\ndata = np.zeros((n,n))\nfor i, lev in enumerate(levs1):\n    j1 = i*10\n    j2 = (i+1)*10\n    data[j1:j2,:] = levs1[i]\n\nprint(data.min(), data.max())\n</pre> n = len(levs1)*10 print(n)  data = np.zeros((n,n)) for i, lev in enumerate(levs1):     j1 = i*10     j2 = (i+1)*10     data[j1:j2,:] = levs1[i]  print(data.min(), data.max()) <pre>90\n0.0001 10000.0\n</pre> In\u00a0[4]: Copied! <pre>fig, axs = plt.subplots(1,3, figsize=(14,4))\nax = axs[0]\np1 = ax.pcolormesh(data, norm=matplotlib.colors.LogNorm(vmin=levs1[0], vmax=levs1[-1]))\nplt.colorbar(p1, ax=ax)\nax.set_title('pcolormesh')\n\n# Repeated color on lower limit =&gt; shows only diff colors for values &gt; 1e-3\nax = axs[1]\np1 = ax.contourf(data, levels=levs1, norm=matplotlib.colors.LogNorm(vmin=levs1[0], vmax=levs1[-1]))\nplt.colorbar(p1, ax=ax)\nax.set_title('contourf')\n\n# Mask ok upper limit (v &gt; 1e-3)\n# Mask lower limit (v &lt; 1e-2)\nax = axs[2]\np1 = ax.contourf(data, levels=levs2, norm=matplotlib.colors.LogNorm(vmin=levs2[0], vmax=levs2[-1]))\nplt.colorbar(p1, ax=ax)\nax.set_title('contourf &amp; levs2')\n</pre> fig, axs = plt.subplots(1,3, figsize=(14,4)) ax = axs[0] p1 = ax.pcolormesh(data, norm=matplotlib.colors.LogNorm(vmin=levs1[0], vmax=levs1[-1])) plt.colorbar(p1, ax=ax) ax.set_title('pcolormesh')  # Repeated color on lower limit =&gt; shows only diff colors for values &gt; 1e-3 ax = axs[1] p1 = ax.contourf(data, levels=levs1, norm=matplotlib.colors.LogNorm(vmin=levs1[0], vmax=levs1[-1])) plt.colorbar(p1, ax=ax) ax.set_title('contourf')  # Mask ok upper limit (v &gt; 1e-3) # Mask lower limit (v &lt; 1e-2) ax = axs[2] p1 = ax.contourf(data, levels=levs2, norm=matplotlib.colors.LogNorm(vmin=levs2[0], vmax=levs2[-1])) plt.colorbar(p1, ax=ax) ax.set_title('contourf &amp; levs2') Out[4]: <pre>Text(0.5, 1.0, 'contourf &amp; levs2')</pre> In\u00a0[5]: Copied! <pre>da = xr.DataArray(data)\n\nfig, axs = plt.subplots(1,3, figsize=(14,4))\nax = axs[0]\nda.plot(ax=ax, norm=matplotlib.colors.LogNorm(vmin=levs1[0], vmax=levs1[-1]))\nax.set_title('pcolormesh')\n\n# Repeats color on upper limit =&gt; All values above v &gt; 1e3 are same\nax = axs[1]\nda.plot(ax=ax, levels=levs1, norm=matplotlib.colors.LogNorm(vmin=levs1[0], vmax=levs1[-1]))\nax.set_title('contourf')\n\n# Repeats color on upper limit =&gt; Values 1e2 &amp; 1e3 same cat, then yellow for v &gt; 1e3\nax = axs[2]\nda.plot(ax=ax, levels=levs2, norm=matplotlib.colors.LogNorm(vmin=levs2[0], vmax=levs2[-1]))\nax.set_title('contourf &amp; levs2')\n\nfig.suptitle('DataArray - plot')\n</pre> da = xr.DataArray(data)  fig, axs = plt.subplots(1,3, figsize=(14,4)) ax = axs[0] da.plot(ax=ax, norm=matplotlib.colors.LogNorm(vmin=levs1[0], vmax=levs1[-1])) ax.set_title('pcolormesh')  # Repeats color on upper limit =&gt; All values above v &gt; 1e3 are same ax = axs[1] da.plot(ax=ax, levels=levs1, norm=matplotlib.colors.LogNorm(vmin=levs1[0], vmax=levs1[-1])) ax.set_title('contourf')  # Repeats color on upper limit =&gt; Values 1e2 &amp; 1e3 same cat, then yellow for v &gt; 1e3 ax = axs[2] da.plot(ax=ax, levels=levs2, norm=matplotlib.colors.LogNorm(vmin=levs2[0], vmax=levs2[-1])) ax.set_title('contourf &amp; levs2')  fig.suptitle('DataArray - plot') Out[5]: <pre>Text(0.5, 0.98, 'DataArray - plot')</pre> In\u00a0[6]: Copied! <pre>da = xr.DataArray(data)\n\nfig, axs = plt.subplots(1,3, figsize=(14,4))\nax = axs[0]\nda.plot.pcolormesh(ax=ax, norm=matplotlib.colors.LogNorm(vmin=levs1[0], vmax=levs1[-1]))\nax.set_title('pcolormesh')\n\nax = axs[1]\nda.plot.contourf(ax=ax, levels=levs1, norm=matplotlib.colors.LogNorm(vmin=levs1[0], vmax=levs1[-1]))\nax.set_title('contourf')\n\nax = axs[2]\nda.plot.contourf(ax=ax, levels=levs2, norm=matplotlib.colors.LogNorm(vmin=levs2[0], vmax=levs2[-1]))\nax.set_title('contourf &amp; levs2')\n\nfig.suptitle('DataArray - plot specific')\n</pre> da = xr.DataArray(data)  fig, axs = plt.subplots(1,3, figsize=(14,4)) ax = axs[0] da.plot.pcolormesh(ax=ax, norm=matplotlib.colors.LogNorm(vmin=levs1[0], vmax=levs1[-1])) ax.set_title('pcolormesh')  ax = axs[1] da.plot.contourf(ax=ax, levels=levs1, norm=matplotlib.colors.LogNorm(vmin=levs1[0], vmax=levs1[-1])) ax.set_title('contourf')  ax = axs[2] da.plot.contourf(ax=ax, levels=levs2, norm=matplotlib.colors.LogNorm(vmin=levs2[0], vmax=levs2[-1])) ax.set_title('contourf &amp; levs2')  fig.suptitle('DataArray - plot specific') Out[6]: <pre>Text(0.5, 0.98, 'DataArray - plot specific')</pre> In\u00a0[7]: Copied! <pre># https://stackoverflow.com/questions/48613920/use-of-extend-in-a-pcolormesh-plot-with-discrete-colorbar\n\ncmap_name = 'viridis'\ncmap = plt.cm.get_cmap('viridis', len(levs2)+1)\ncolors = list(cmap(np.arange(len(levs2)+1)))\n\n# replace extended colors\ncolors[0] = \"white\"\ncolors[-1] = 'red'\n\ncmap2 = matplotlib.colors.ListedColormap(colors)\n# can also be done like this\n# cmap2.set_over('red')\n</pre> # https://stackoverflow.com/questions/48613920/use-of-extend-in-a-pcolormesh-plot-with-discrete-colorbar  cmap_name = 'viridis' cmap = plt.cm.get_cmap('viridis', len(levs2)+1) colors = list(cmap(np.arange(len(levs2)+1)))  # replace extended colors colors[0] = \"white\" colors[-1] = 'red'  cmap2 = matplotlib.colors.ListedColormap(colors) # can also be done like this # cmap2.set_over('red')  <pre>/tmp/ipykernel_182442/2249701899.py:4: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n  cmap = plt.cm.get_cmap('viridis', len(levs2)+1)\n</pre> In\u00a0[8]: Copied! <pre># CORRECT: DataArray.plot.contourf with limits on LogNorm\nfig, axs = plt.subplots(1,2, figsize=(10,4))\nda.plot.contourf(ax=axs[0], levels=levs2, cmap=cmap, norm=matplotlib.colors.LogNorm(vmin=levs2[0], vmax=levs2[-1]))\nda.plot.contourf(ax=axs[1], levels=levs2, cmap=cmap2, norm=matplotlib.colors.LogNorm(vmin=levs2[0], vmax=levs2[-1]))\n</pre> # CORRECT: DataArray.plot.contourf with limits on LogNorm fig, axs = plt.subplots(1,2, figsize=(10,4)) da.plot.contourf(ax=axs[0], levels=levs2, cmap=cmap, norm=matplotlib.colors.LogNorm(vmin=levs2[0], vmax=levs2[-1])) da.plot.contourf(ax=axs[1], levels=levs2, cmap=cmap2, norm=matplotlib.colors.LogNorm(vmin=levs2[0], vmax=levs2[-1])) Out[8]: <pre>&lt;matplotlib.contour.QuadContourSet at 0x7f8e776dbd90&gt;</pre> In\u00a0[9]: Copied! <pre># BAD: DataArray.plot =&gt; Inconsistent with contourf\nfig, axs = plt.subplots(1,2, figsize=(10,4))\nda.plot(ax=axs[0], levels=levs2, cmap=cmap, norm=matplotlib.colors.LogNorm(vmin=levs2[0], vmax=levs2[-1]))\nda.plot(ax=axs[1], levels=levs2, cmap=cmap2, norm=matplotlib.colors.LogNorm(vmin=levs2[0], vmax=levs2[-1]))\n</pre> # BAD: DataArray.plot =&gt; Inconsistent with contourf fig, axs = plt.subplots(1,2, figsize=(10,4)) da.plot(ax=axs[0], levels=levs2, cmap=cmap, norm=matplotlib.colors.LogNorm(vmin=levs2[0], vmax=levs2[-1])) da.plot(ax=axs[1], levels=levs2, cmap=cmap2, norm=matplotlib.colors.LogNorm(vmin=levs2[0], vmax=levs2[-1])) Out[9]: <pre>&lt;matplotlib.collections.QuadMesh at 0x7f8e777bfc50&gt;</pre> In\u00a0[10]: Copied! <pre># BAD: DataArray.plot without limits on LogNorm =&gt; Inconsistent colors..\nfig, axs = plt.subplots(1,2, figsize=(10,4))\nda.plot(ax=axs[0], levels=levs2, cmap=cmap, norm=matplotlib.colors.LogNorm())\nda.plot(ax=axs[1], levels=levs2, cmap=cmap2, norm=matplotlib.colors.LogNorm())\n</pre> # BAD: DataArray.plot without limits on LogNorm =&gt; Inconsistent colors.. fig, axs = plt.subplots(1,2, figsize=(10,4)) da.plot(ax=axs[0], levels=levs2, cmap=cmap, norm=matplotlib.colors.LogNorm()) da.plot(ax=axs[1], levels=levs2, cmap=cmap2, norm=matplotlib.colors.LogNorm()) Out[10]: <pre>&lt;matplotlib.collections.QuadMesh at 0x7f8e784c2850&gt;</pre> In\u00a0[11]: Copied! <pre># BAD: DataArray.plot.contourf without limits on LogNorm =&gt; Inconsistent colors..\nfig, axs = plt.subplots(1,2, figsize=(10,4))\nda.plot.contourf(ax=axs[0], levels=levs2, cmap=cmap, norm=matplotlib.colors.LogNorm())\nda.plot.contourf(ax=axs[1], levels=levs2, cmap=cmap2, norm=matplotlib.colors.LogNorm())\n</pre> # BAD: DataArray.plot.contourf without limits on LogNorm =&gt; Inconsistent colors.. fig, axs = plt.subplots(1,2, figsize=(10,4)) da.plot.contourf(ax=axs[0], levels=levs2, cmap=cmap, norm=matplotlib.colors.LogNorm()) da.plot.contourf(ax=axs[1], levels=levs2, cmap=cmap2, norm=matplotlib.colors.LogNorm()) Out[11]: <pre>&lt;matplotlib.contour.QuadContourSet at 0x7f8e779b2210&gt;</pre> In\u00a0[12]: Copied! <pre>cmap\n</pre> cmap Out[12]: viridis  underbad over  In\u00a0[13]: Copied! <pre>cmap2\n</pre> cmap2 Out[13]: from_list  underbad over  In\u00a0[14]: Copied! <pre>cmap2.N\n</pre> cmap2.N Out[14]: <pre>8</pre> In\u00a0[15]: Copied! <pre>levs1, levs2\n</pre> levs1, levs2 Out[15]: <pre>(array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03,\n        1.e+04]),\n array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]))</pre> In\u00a0[16]: Copied! <pre># http://omz-software.com/pythonista/matplotlib/examples/api/colorbar_only.html\n\nfig, axs = plt.subplots(1,2, figsize=(10,4))\nda.plot.contourf(ax=axs[0], levels=levs2, cmap=cmap2, norm=matplotlib.colors.LogNorm(vmin=levs2[0], vmax=levs2[-1]), add_colorbar=False)\nda.plot.contourf(ax=axs[1], levels=levs2, cmap=cmap2, norm=matplotlib.colors.LogNorm(vmin=levs2[0], vmax=levs2[-1]), add_colorbar=False)\n\nfig.subplots_adjust(right=0.85)\ncbar_ax = fig.add_axes([0.88, 0.15, 0.03, 0.7])\n# Doesn't do the extend (deprecated matplotlib +3.3)\n# cb = fig.colorbar(p1, cax=cbar_ax, extend='both')\n\ncb = matplotlib.colorbar.ColorbarBase(ax=cbar_ax,\n    cmap=cmap2,\n    norm=matplotlib.colors.LogNorm(vmin=levs1[0], vmax=levs1[-1]),\n    # to use 'extend', you must\n    # specify two extra boundaries:\n    boundaries=levs1, #[0]+bounds+[13],\n    extend='both',\n#     ticks=levs2, # optional\n    spacing='proportional',\n)\n\ncb.set_label('colorbar label')\n</pre> # http://omz-software.com/pythonista/matplotlib/examples/api/colorbar_only.html  fig, axs = plt.subplots(1,2, figsize=(10,4)) da.plot.contourf(ax=axs[0], levels=levs2, cmap=cmap2, norm=matplotlib.colors.LogNorm(vmin=levs2[0], vmax=levs2[-1]), add_colorbar=False) da.plot.contourf(ax=axs[1], levels=levs2, cmap=cmap2, norm=matplotlib.colors.LogNorm(vmin=levs2[0], vmax=levs2[-1]), add_colorbar=False)  fig.subplots_adjust(right=0.85) cbar_ax = fig.add_axes([0.88, 0.15, 0.03, 0.7]) # Doesn't do the extend (deprecated matplotlib +3.3) # cb = fig.colorbar(p1, cax=cbar_ax, extend='both')  cb = matplotlib.colorbar.ColorbarBase(ax=cbar_ax,     cmap=cmap2,     norm=matplotlib.colors.LogNorm(vmin=levs1[0], vmax=levs1[-1]),     # to use 'extend', you must     # specify two extra boundaries:     boundaries=levs1, #[0]+bounds+[13],     extend='both', #     ticks=levs2, # optional     spacing='proportional', )  cb.set_label('colorbar label') In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"miscellaneous/plot_colorbar_lognorm/#plot-lognorm-colorbar","title":"Plot lognorm colorbar\u00b6","text":"<p>To be reviewed...</p>"},{"location":"miscellaneous/plot_colorbar_lognorm/#numpy","title":"Numpy\u00b6","text":""},{"location":"miscellaneous/plot_colorbar_lognorm/#pcolormesh-vs-contourf","title":"pcolormesh vs contourf\u00b6","text":""},{"location":"miscellaneous/plot_colorbar_lognorm/#dataarray","title":"DataArray\u00b6","text":""},{"location":"miscellaneous/plot_colorbar_lognorm/#pcolormesh-vs-contourf","title":"pcolormesh vs contourf\u00b6","text":"<p>DataArray.plot(levels=) behaves different than contourf</p> <p>weird logic with levs1 and levs2</p>"},{"location":"miscellaneous/plot_colorbar_lognorm/#pcolormesh-vs-contourf-v2","title":"pcolormesh vs contourf - V2\u00b6","text":"<p>DataArray.plot(levels=) differs from DataArray.plot.contourf(levels=)</p> <p>DataArray.plot.contourf(levels=) still has repeated color but consistent with levs1 or levs2</p>"},{"location":"miscellaneous/plot_colorbar_lognorm/#contourf-extended","title":"contourf + extended\u00b6","text":"<p>Conclusion: Need to set limits on LogNorm for consistent coloring of levels</p>"},{"location":"miscellaneous/plot_colorbar_lognorm/#contourf-extend-with-matplotlib-33","title":"contourf + extend with matplotlib +3.3\u00b6","text":"<p>http://omz-software.com/pythonista/matplotlib/examples/api/colorbar_only.html</p>"},{"location":"miscellaneous/plot_image_overlay_folium_ipyleaflet/","title":"Overlay png image on folium and ipyleaflet","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport folium\nimport ipyleaflet\nfrom base64 import b64encode\n\nvmin = 0\nvmax = 2000\n\nimport matplotlib\ncmap = matplotlib.cm.get_cmap(\"viridis\")\n\n# testing - not used here\nimport branca.colormap as cm\nbcmap = cm.linear.viridis.scale(vmin=vmin, vmax=vmax).to_step(n=4)\nbcmap.caption = 'my color scale'\nbcmap\n</pre> import numpy as np import matplotlib.pyplot as plt import folium import ipyleaflet from base64 import b64encode  vmin = 0 vmax = 2000  import matplotlib cmap = matplotlib.cm.get_cmap(\"viridis\")  # testing - not used here import branca.colormap as cm bcmap = cm.linear.viridis.scale(vmin=vmin, vmax=vmax).to_step(n=4) bcmap.caption = 'my color scale' bcmap  <pre>/tmp/ipykernel_182489/3982767682.py:11: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n  cmap = matplotlib.cm.get_cmap(\"viridis\")\n</pre> Out[1]: 0.0333.3666.71000.01333.31666.72000.0my color scale In\u00a0[2]: Copied! <pre>n = 5\ndata = np.zeros((n, n))\n\n# borders are vmax\ndata[0, :] = vmax\ndata[-1, :] = vmax\ndata[:, 0] = vmax\ndata[:, -1] = vmax\n\n# diagonal is vmax/2\nfor i in np.arange(n):\n    data[i,i] = vmax/2\n\n# central point is nan (see transparencu)\ndata[int(n/2),int(n/2)] = np.nan\n\nprint(data)\n\nplt.imshow(data, cmap=cmap)\nplt.colorbar()\n</pre> n = 5 data = np.zeros((n, n))  # borders are vmax data[0, :] = vmax data[-1, :] = vmax data[:, 0] = vmax data[:, -1] = vmax  # diagonal is vmax/2 for i in np.arange(n):     data[i,i] = vmax/2  # central point is nan (see transparencu) data[int(n/2),int(n/2)] = np.nan  print(data)  plt.imshow(data, cmap=cmap) plt.colorbar() <pre>[[1000. 2000. 2000. 2000. 2000.]\n [2000. 1000.    0.    0. 2000.]\n [2000.    0.   nan    0. 2000.]\n [2000.    0.    0. 1000. 2000.]\n [2000. 2000. 2000. 2000. 1000.]]\n</pre> Out[2]: <pre>&lt;matplotlib.colorbar.Colorbar at 0x7103f07c1940&gt;</pre> In\u00a0[3]: Copied! <pre># this still saves fig with border\n# plt.imshow(data, cmap=cmap, aspect='equal', vmin=vmin, vmax=vmax)\n# plt.axis('off')\n# plt.savefig('temp.png', transparent=True, bbox_inches='tight', dpi=500)\n</pre> # this still saves fig with border # plt.imshow(data, cmap=cmap, aspect='equal', vmin=vmin, vmax=vmax) # plt.axis('off') # plt.savefig('temp.png', transparent=True, bbox_inches='tight', dpi=500)  In\u00a0[4]: Copied! <pre>fig = plt.figure(figsize=(1, 1))\nax = plt.Axes(fig, [0., 0., 1., 1.])\nax.set_axis_off()\nfig.add_axes(ax)\nax.imshow(data, cmap=cmap, aspect='equal', vmin=vmin, vmax=vmax)\nfig.savefig('temp.png', dpi=500)\n</pre> fig = plt.figure(figsize=(1, 1)) ax = plt.Axes(fig, [0., 0., 1., 1.]) ax.set_axis_off() fig.add_axes(ax) ax.imshow(data, cmap=cmap, aspect='equal', vmin=vmin, vmax=vmax) fig.savefig('temp.png', dpi=500) In\u00a0[5]: Copied! <pre>with open('temp.png', \"rb\") as f:\n    data1 = b64encode(f.read())\n    data1 = data1.decode(\"ascii\")\n    imgurl = \"data:image/png;base64,\" + data1\n</pre> with open('temp.png', \"rb\") as f:     data1 = b64encode(f.read())     data1 = data1.decode(\"ascii\")     imgurl = \"data:image/png;base64,\" + data1 In\u00a0[6]: Copied! <pre># bottom left\nx1,y1 = 175,-39\n\n# bottom left\n# x1,y1 = -5,39\n\nx2,y2 = x1+n,y1+n\nprint(x1,x2,y1,y2)\n\nbounds = [[y1, x1], [y2, x2]]\ncenter = [(y1+y2)/2, (x1+x2)/2]\nprint(center)\n</pre> # bottom left x1,y1 = 175,-39  # bottom left # x1,y1 = -5,39  x2,y2 = x1+n,y1+n print(x1,x2,y1,y2)  bounds = [[y1, x1], [y2, x2]] center = [(y1+y2)/2, (x1+x2)/2] print(center)  <pre>175 180 -39 -34\n[-36.5, 177.5]\n</pre> In\u00a0[7]: Copied! <pre>def get_latlon_gridlines(window=[-180,180,-90,90], dx=10,dy=10):\n    x1,x2,y1,y2 = window\n    gridlines = []\n    # parallels for each lat\n    for lat in np.arange(y1, y2+dy/2, dy):\n        gridlines += [([lat,x1], [lat,x2])]\n    # meridians for each lon\n    for lon in  np.arange(x1, x2+dx/2, dx):\n        gridlines += [([y1,lon], [y2,lon])]\n\n    return(gridlines)\n\ngridlines = get_latlon_gridlines(window=[x1,x2,y1,y2], dx=1,dy=1)\n</pre> def get_latlon_gridlines(window=[-180,180,-90,90], dx=10,dy=10):     x1,x2,y1,y2 = window     gridlines = []     # parallels for each lat     for lat in np.arange(y1, y2+dy/2, dy):         gridlines += [([lat,x1], [lat,x2])]     # meridians for each lon     for lon in  np.arange(x1, x2+dx/2, dx):         gridlines += [([y1,lon], [y2,lon])]      return(gridlines)  gridlines = get_latlon_gridlines(window=[x1,x2,y1,y2], dx=1,dy=1) In\u00a0[8]: Copied! <pre>gridlines\n</pre> gridlines Out[8]: <pre>[([np.float64(-39.0), 175], [np.float64(-39.0), 180]),\n ([np.float64(-38.0), 175], [np.float64(-38.0), 180]),\n ([np.float64(-37.0), 175], [np.float64(-37.0), 180]),\n ([np.float64(-36.0), 175], [np.float64(-36.0), 180]),\n ([np.float64(-35.0), 175], [np.float64(-35.0), 180]),\n ([np.float64(-34.0), 175], [np.float64(-34.0), 180]),\n ([-39, np.float64(175.0)], [-34, np.float64(175.0)]),\n ([-39, np.float64(176.0)], [-34, np.float64(176.0)]),\n ([-39, np.float64(177.0)], [-34, np.float64(177.0)]),\n ([-39, np.float64(178.0)], [-34, np.float64(178.0)]),\n ([-39, np.float64(179.0)], [-34, np.float64(179.0)]),\n ([-39, np.float64(180.0)], [-34, np.float64(180.0)])]</pre> In\u00a0[9]: Copied! <pre>import os\ncurr_dir = os.getcwd()\ncurr_dir\n</pre> import os curr_dir = os.getcwd() curr_dir Out[9]: <pre>'/home/rosa/git/rosatrancoso/notebook-share/docs/miscellaneous'</pre> In\u00a0[10]: Copied! <pre>m = folium.Map(center, zoom_start=2)\n\nfolium.PolyLine(gridlines, color='gray', weight=0.5, name='gridlines').add_to(m)\n\nfolium.raster_layers.ImageOverlay(\n    name='raw data',\n    image=data,\n    bounds=bounds,\n    colormap=cmap,\n    vmin=vmin, vmax=vmax,\n    opacity=0.6,\n).add_to(m)\n\nfolium.raster_layers.ImageOverlay(\n    name='png file',\n    image=os.path.join(curr_dir, 'temp.png'),\n    bounds=bounds,\n    opacity=0.6,\n).add_to(m)\n\nfolium.raster_layers.ImageOverlay(\n    name='png base64',\n    image=imgurl,\n    bounds=bounds,\n    opacity=0.6,\n).add_to(m)\n\n\n\nm.add_child(folium.map.LayerControl(position='topleft', collapsed=False))\nm.fit_bounds(m.get_bounds(),max_zoom=14)\n\n# maybe we could do a colormap based on ColorLine\n# folium.ColorLine(positions=[[70,-60],[70,0], [70,60]], colors=[0,1], colormap=['r','g'], weigth=10).add_to(m)\n\nm\n</pre> m = folium.Map(center, zoom_start=2)  folium.PolyLine(gridlines, color='gray', weight=0.5, name='gridlines').add_to(m)  folium.raster_layers.ImageOverlay(     name='raw data',     image=data,     bounds=bounds,     colormap=cmap,     vmin=vmin, vmax=vmax,     opacity=0.6, ).add_to(m)  folium.raster_layers.ImageOverlay(     name='png file',     image=os.path.join(curr_dir, 'temp.png'),     bounds=bounds,     opacity=0.6, ).add_to(m)  folium.raster_layers.ImageOverlay(     name='png base64',     image=imgurl,     bounds=bounds,     opacity=0.6, ).add_to(m)    m.add_child(folium.map.LayerControl(position='topleft', collapsed=False)) m.fit_bounds(m.get_bounds(),max_zoom=14)  # maybe we could do a colormap based on ColorLine # folium.ColorLine(positions=[[70,-60],[70,0], [70,60]], colors=[0,1], colormap=['r','g'], weigth=10).add_to(m)  m Out[10]: Make this Notebook Trusted to load map: File -&gt; Trust Notebook In\u00a0[11]: Copied! <pre>m = ipyleaflet.Map(center=center, zoom=4)\n\nm.add_layer(\n    ipyleaflet.Polyline(\n        locations=gridlines,\n        color=\"gray\" ,\n        fill=False,\n        weight=1\n    )\n)\n\n# TraitError: The 'url' trait of an ImageOverlay instance expected a unicode string, not the ndarray array([[1000., 1000., 1000., ..., 2000., 2000., 2000.],\n# m.add_layer(\n#     ipyleaflet.ImageOverlay(\n#         url=data,\n#         bounds=bounds,\n#         colormap=cmap\n#     )\n# )\n\nm.add_layer(\n    ipyleaflet.ImageOverlay(\n        url=imgurl,\n        bounds=bounds,\n        colormap=cmap\n    )\n)\n\nm\n</pre> m = ipyleaflet.Map(center=center, zoom=4)  m.add_layer(     ipyleaflet.Polyline(         locations=gridlines,         color=\"gray\" ,         fill=False,         weight=1     ) )  # TraitError: The 'url' trait of an ImageOverlay instance expected a unicode string, not the ndarray array([[1000., 1000., 1000., ..., 2000., 2000., 2000.], # m.add_layer( #     ipyleaflet.ImageOverlay( #         url=data, #         bounds=bounds, #         colormap=cmap #     ) # )  m.add_layer(     ipyleaflet.ImageOverlay(         url=imgurl,         bounds=bounds,         colormap=cmap     ) )  m Out[11]: <pre>Map(center=[-36.5, 177.5], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom_o\u2026</pre>"},{"location":"miscellaneous/plot_image_overlay_folium_ipyleaflet/#overlay-png-image-on-folium-and-ipyleaflet","title":"Overlay png image on folium and ipyleaflet\u00b6","text":""},{"location":"miscellaneous/plot_image_overlay_folium_ipyleaflet/#set-up-test-data-and-save-as-png","title":"Set up test data and save as png\u00b6","text":""},{"location":"miscellaneous/plot_image_overlay_folium_ipyleaflet/#read-png-as-base64","title":"Read png as base64\u00b6","text":""},{"location":"miscellaneous/plot_image_overlay_folium_ipyleaflet/#get-gridlines","title":"Get gridlines\u00b6","text":""},{"location":"miscellaneous/plot_image_overlay_folium_ipyleaflet/#plot","title":"Plot\u00b6","text":""},{"location":"miscellaneous/plot_image_overlay_folium_ipyleaflet/#folium","title":"folium\u00b6","text":"<ul> <li>raw data ok but weird color scale</li> <li>png file and base64 are ok if png doesn't have border!</li> </ul>"},{"location":"miscellaneous/plot_image_overlay_folium_ipyleaflet/#ipyleaflet","title":"ipyleaflet\u00b6","text":"<ul> <li>doesn't plot raw data (np.array)</li> <li>png base64 is ok</li> </ul>"},{"location":"miscellaneous/plot_image_overlay_ipyleaflet_terrain/","title":"Overlay tif image on ipyleaflet","text":"In\u00a0[\u00a0]: Copied! <pre>! wget https://data.hydrosheds.org/file/hydrosheds-v1-con/au_con_3s/s40e170_con.zip\n</pre> ! wget https://data.hydrosheds.org/file/hydrosheds-v1-con/au_con_3s/s40e170_con.zip In\u00a0[\u00a0]: Copied! <pre>! unzip -o s40e170_con.zip\n</pre> ! unzip -o s40e170_con.zip In\u00a0[\u00a0]: Copied! <pre>! gdalinfo s40e170_con.tif\n</pre> ! gdalinfo s40e170_con.tif In\u00a0[\u00a0]: Copied! <pre>%%bash\n\nexport PROJ_LIB=\"$CONDA_PREFIX/share/proj\"\nrm -rf s40e170_con_merc.tif\ngdalwarp -s_srs epsg:4326 -t_srs epsg:3857 s40e170_con.tif s40e170_con_merc.tif\n</pre> %%bash  export PROJ_LIB=\"$CONDA_PREFIX/share/proj\" rm -rf s40e170_con_merc.tif gdalwarp -s_srs epsg:4326 -t_srs epsg:3857 s40e170_con.tif s40e170_con_merc.tif In\u00a0[\u00a0]: Copied! <pre>import rasterio\nimport matplotlib.pyplot as plt\nimport copy\nfrom base64 import b64encode\nimport numpy as np\nimport ipyleaflet\n\ncmap = copy.copy(plt.get_cmap('jet'))\ncmap.set_under('k', alpha=0)\n\ndef geotiff_to_png(filein, fileout, cmap='jet', vmin=0.1, vmax=2000, mask_value=32767):\n\n    print(f'Reading {filein}')\n    src = rasterio.open(filein)\n    print(src.crs.to_proj4())\n    print(src.bounds)\n\n    data = src.read(1)\n    print(data.shape, data.min(), data.max())\n    data = np.where(data == mask_value, np.nan, data)\n    print(data.shape, np.nanmin(data), np.nanmax(data))\n\n    print(f'Plotting into {fileout}')\n    plt.imshow(data, cmap=cmap, aspect='equal', vmin=vmin, vmax=vmax)\n    plt.axis('off')\n    plt.savefig(fileout, transparent=True, bbox_inches='tight', dpi=500,pad_inches = 0)\n    plt.show()\n    plt.close()\n\ndef get_latlon_gridlines(window=[-180,180,-90,90], dx=10,dy=10):\n    x1,x2,y1,y2 = window\n    gridlines = []\n    # parallels for each lat\n    for lat in np.arange(y1, y2+dy/2, dy):\n        gridlines += [([lat,x1], [lat,x2])]\n    # meridians for each lon\n    for lon in  np.arange(x1, x2+dx/2, dx):\n        gridlines += [([y1,lon], [y2,lon])]\n\n    return(gridlines)\n</pre> import rasterio import matplotlib.pyplot as plt import copy from base64 import b64encode import numpy as np import ipyleaflet  cmap = copy.copy(plt.get_cmap('jet')) cmap.set_under('k', alpha=0)  def geotiff_to_png(filein, fileout, cmap='jet', vmin=0.1, vmax=2000, mask_value=32767):      print(f'Reading {filein}')     src = rasterio.open(filein)     print(src.crs.to_proj4())     print(src.bounds)      data = src.read(1)     print(data.shape, data.min(), data.max())     data = np.where(data == mask_value, np.nan, data)     print(data.shape, np.nanmin(data), np.nanmax(data))      print(f'Plotting into {fileout}')     plt.imshow(data, cmap=cmap, aspect='equal', vmin=vmin, vmax=vmax)     plt.axis('off')     plt.savefig(fileout, transparent=True, bbox_inches='tight', dpi=500,pad_inches = 0)     plt.show()     plt.close()  def get_latlon_gridlines(window=[-180,180,-90,90], dx=10,dy=10):     x1,x2,y1,y2 = window     gridlines = []     # parallels for each lat     for lat in np.arange(y1, y2+dy/2, dy):         gridlines += [([lat,x1], [lat,x2])]     # meridians for each lon     for lon in  np.arange(x1, x2+dx/2, dx):         gridlines += [([y1,lon], [y2,lon])]      return(gridlines) In\u00a0[\u00a0]: Copied! <pre>geotiff_to_png('s40e170_con_merc.tif', 's40e170_con_merc.png', cmap='jet')\n</pre> geotiff_to_png('s40e170_con_merc.tif', 's40e170_con_merc.png', cmap='jet') In\u00a0[\u00a0]: Copied! <pre>! gdalinfo s40e170_con.tif\n</pre> ! gdalinfo s40e170_con.tif In\u00a0[\u00a0]: Copied! <pre># bounds = ((miny, minx), (maxy, maxx))\nx1,x2,y1,y2 = 170,180,-40,-30\nbounds = ((y1, x1), (y2,x2))\nprint(bounds)\n\ngridlines = get_latlon_gridlines(window=[x1,x2,y1,y2], dx=1,dy=1)\n</pre> # bounds = ((miny, minx), (maxy, maxx)) x1,x2,y1,y2 = 170,180,-40,-30 bounds = ((y1, x1), (y2,x2)) print(bounds)  gridlines = get_latlon_gridlines(window=[x1,x2,y1,y2], dx=1,dy=1)  In\u00a0[\u00a0]: Copied! <pre>m = ipyleaflet.Map(center=[-40,170], zoom = 4, scroll_wheel_zoom=True)\n\n\nm.add_layer(\n    ipyleaflet.Polyline(\n        name='gridlines',\n        locations=gridlines,\n        color=\"gray\" ,\n        fill=False,\n        weight=1\n    )\n)\n\nwith open('s40e170_con_merc.png', \"rb\") as f:\n    data = b64encode(f.read())\n    data = data.decode(\"ascii\")\n    imgurl = \"data:image/png;base64,\" + data\n\nimage = ipyleaflet.ImageOverlay(url=imgurl, bounds=bounds, opacity=0.4, name='merc')\nm.add_layer(image)\n\nm.add_control(ipyleaflet.LayersControl())\nm\n</pre>  m = ipyleaflet.Map(center=[-40,170], zoom = 4, scroll_wheel_zoom=True)   m.add_layer(     ipyleaflet.Polyline(         name='gridlines',         locations=gridlines,         color=\"gray\" ,         fill=False,         weight=1     ) )  with open('s40e170_con_merc.png', \"rb\") as f:     data = b64encode(f.read())     data = data.decode(\"ascii\")     imgurl = \"data:image/png;base64,\" + data  image = ipyleaflet.ImageOverlay(url=imgurl, bounds=bounds, opacity=0.4, name='merc') m.add_layer(image)  m.add_control(ipyleaflet.LayersControl()) m"},{"location":"miscellaneous/plot_image_overlay_ipyleaflet_terrain/#overlay-tif-image-on-ipyleaflet","title":"Overlay tif image on ipyleaflet\u00b6","text":"<p>Crashing. To be reviewed...</p>"},{"location":"miscellaneous/test_xarray_leaflet_simple/","title":"Test xarray_leaflet","text":"In\u00a0[11]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport xarray as xr\nimport xarray_leaflet\nimport ipyleaflet\nimport rioxarray\n</pre> import numpy as np import matplotlib.pyplot as plt import xarray as xr import xarray_leaflet import ipyleaflet import rioxarray In\u00a0[12]: Copied! <pre>z=1500\n\nimage = np.zeros((61, 61))\nimage[0, :] = z\nimage[60, :] = z\nimage[:, 0] = z\nimage[:, 60] = z\nimage[:10,:10] = 1000\nimage[10:20,10:20] = 500\nimage[20:30,20:30] = np.nan\n\nprint(image)\n\nplt.imshow(image)\nplt.colorbar()\n</pre> z=1500  image = np.zeros((61, 61)) image[0, :] = z image[60, :] = z image[:, 0] = z image[:, 60] = z image[:10,:10] = 1000 image[10:20,10:20] = 500 image[20:30,20:30] = np.nan  print(image)  plt.imshow(image) plt.colorbar() <pre>[[1000. 1000. 1000. ... 1500. 1500. 1500.]\n [1000. 1000. 1000. ...    0.    0. 1500.]\n [1000. 1000. 1000. ...    0.    0. 1500.]\n ...\n [1500.    0.    0. ...    0.    0. 1500.]\n [1500.    0.    0. ...    0.    0. 1500.]\n [1500. 1500. 1500. ... 1500. 1500. 1500.]]\n</pre> Out[12]: <pre>&lt;matplotlib.colorbar.Colorbar at 0x7f0dbf3d3390&gt;</pre> In\u00a0[13]: Copied! <pre>da = xr.DataArray(image, dims=['y','x'], coords=dict(x=np.arange(-60,61,2), y=np.arange(61,0,-1)))\nda\n</pre> da = xr.DataArray(image, dims=['y','x'], coords=dict(x=np.arange(-60,61,2), y=np.arange(61,0,-1))) da Out[13]: <pre>&lt;xarray.DataArray (y: 61, x: 61)&gt; Size: 30kB\narray([[1000., 1000., 1000., ..., 1500., 1500., 1500.],\n       [1000., 1000., 1000., ...,    0.,    0., 1500.],\n       [1000., 1000., 1000., ...,    0.,    0., 1500.],\n       ...,\n       [1500.,    0.,    0., ...,    0.,    0., 1500.],\n       [1500.,    0.,    0., ...,    0.,    0., 1500.],\n       [1500., 1500., 1500., ..., 1500., 1500., 1500.]], shape=(61, 61))\nCoordinates:\n  * x        (x) int64 488B -60 -58 -56 -54 -52 -50 -48 ... 48 50 52 54 56 58 60\n  * y        (y) int64 488B 61 60 59 58 57 56 55 54 53 52 ... 9 8 7 6 5 4 3 2 1</pre>xarray.DataArray<ul><li>y: 61</li><li>x: 61</li></ul><ul><li>1e+03 1e+03 1e+03 1e+03 1e+03 ... 1.5e+03 1.5e+03 1.5e+03 1.5e+03<pre>array([[1000., 1000., 1000., ..., 1500., 1500., 1500.],\n       [1000., 1000., 1000., ...,    0.,    0., 1500.],\n       [1000., 1000., 1000., ...,    0.,    0., 1500.],\n       ...,\n       [1500.,    0.,    0., ...,    0.,    0., 1500.],\n       [1500.,    0.,    0., ...,    0.,    0., 1500.],\n       [1500., 1500., 1500., ..., 1500., 1500., 1500.]], shape=(61, 61))</pre></li><li>Coordinates: (2)<ul><li>x(x)int64-60 -58 -56 -54 -52 ... 54 56 58 60<pre>array([-60, -58, -56, -54, -52, -50, -48, -46, -44, -42, -40, -38, -36, -34,\n       -32, -30, -28, -26, -24, -22, -20, -18, -16, -14, -12, -10,  -8,  -6,\n        -4,  -2,   0,   2,   4,   6,   8,  10,  12,  14,  16,  18,  20,  22,\n        24,  26,  28,  30,  32,  34,  36,  38,  40,  42,  44,  46,  48,  50,\n        52,  54,  56,  58,  60])</pre></li><li>y(y)int6461 60 59 58 57 56 ... 6 5 4 3 2 1<pre>array([61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44,\n       43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26,\n       25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10,  9,  8,\n        7,  6,  5,  4,  3,  2,  1])</pre></li></ul></li><li>Indexes: (2)<ul><li>xPandasIndex<pre>PandasIndex(Index([-60, -58, -56, -54, -52, -50, -48, -46, -44, -42, -40, -38, -36, -34,\n       -32, -30, -28, -26, -24, -22, -20, -18, -16, -14, -12, -10,  -8,  -6,\n        -4,  -2,   0,   2,   4,   6,   8,  10,  12,  14,  16,  18,  20,  22,\n        24,  26,  28,  30,  32,  34,  36,  38,  40,  42,  44,  46,  48,  50,\n        52,  54,  56,  58,  60],\n      dtype='int64', name='x'))</pre></li><li>yPandasIndex<pre>PandasIndex(Index([61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44,\n       43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26,\n       25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10,  9,  8,\n        7,  6,  5,  4,  3,  2,  1],\n      dtype='int64', name='y'))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[14]: Copied! <pre>da.plot()\n</pre> da.plot() Out[14]: <pre>&lt;matplotlib.collections.QuadMesh at 0x7f0dbf28a0d0&gt;</pre> In\u00a0[15]: Copied! <pre>m = ipyleaflet.Map(center=[0, 0], zoom=3)\nda = da.rio.write_crs(4326)  # WGS 84\nda = da.rio.write_nodata(np.nan)\nl = da.leaflet.plot(m)\nm\n</pre> m = ipyleaflet.Map(center=[0, 0], zoom=3) da = da.rio.write_crs(4326)  # WGS 84 da = da.rio.write_nodata(np.nan) l = da.leaflet.plot(m) m <pre>Url()</pre> Out[15]: <pre>Map(center=[0, 0], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom_out_text'\u2026</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"miscellaneous/test_xarray_leaflet_simple/#test-xarray_leaflet","title":"Test xarray_leaflet\u00b6","text":"<p>Doesn't show anything. To be reviewed: Check lib versions.</p>"},{"location":"qva/plot_qva_det/","title":"Plot QVA Deterministic","text":"In\u00a0[1]: Copied! <pre># Contents of the netcdf file\n! ncdump -h qva_det_Ruapehu_202501081200.nc\n</pre> # Contents of the netcdf file ! ncdump -h qva_det_Ruapehu_202501081200.nc <pre>netcdf qva_det_Ruapehu_202501081200 {\ndimensions:\n\ttime = UNLIMITED ; // (24 currently)\n\tlatitude = 361 ;\n\tlongitude = 441 ;\n\tlevels = 12 ;\nvariables:\n\tfloat latitude(latitude) ;\n\t\tlatitude:_FillValue = NaNf ;\n\t\tlatitude:long_name = \"latitude degrees north from the equator\" ;\n\t\tlatitude:units = \"degrees_north\" ;\n\t\tlatitude:point_spacing = \"even\" ;\n\tfloat longitude(longitude) ;\n\t\tlongitude:_FillValue = NaNf ;\n\t\tlongitude:long_name = \"longitude degrees east from the greenwich meridian\" ;\n\t\tlongitude:units = \"degrees_east\" ;\n\t\tlongitude:point_spacing = \"even\" ;\n\tdouble levels(levels) ;\n\t\tlevels:_FillValue = NaN ;\n\t\tlevels:long_name = \"Top of flight level layer\" ;\n\t\tlevels:units = \"feet\" ;\n\t\tlevels:axis = \"Z\" ;\n\t\tlevels:positive = \"up\" ;\n\tint64 time(time) ;\n\t\ttime:axis = \"T\" ;\n\t\ttime:long_name = \"time\" ;\n\t\ttime:units = \"hours since 2025-01-08T13:00:00\" ;\n\t\ttime:calendar = \"proleptic_gregorian\" ;\n\tfloat concentration(time, levels, latitude, longitude) ;\n\t\tconcentration:_FillValue = NaNf ;\n\t\tconcentration:long_name = \"Quantitative volcanic ash concentration from deterministic forecast\" ;\n\t\tconcentration:units = \"mg/m3\" ;\n\n// global attributes:\n\t\t:title = \"HYSPLIT Model Concentration Output\" ;\n\t\t:Conventions = \"CF-1.5\" ;\n\t\t:volcano_name = \"Ruapehu\" ;\n\t\t:eruption_lon_degrees = 175.57f ;\n\t\t:eruption_lat_degrees = -39.28f ;\n\t\t:eruption_vent_meters_msl = 2797.f ;\n\t\t:eruption_height_meters_msl = 12500.f ;\n\t\t:eruption_mass_eruption_rate_kgs = 87500. ;\n\t\t:eruption_start_time = \"2025-01-08T12:00:00\" ;\n\t\t:eruption_duration_s = 3600. ;\n}\n</pre> In\u00a0[2]: Copied! <pre>import numpy as np\nimport pandas as pd \nimport xarray as xr\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\nimport cartopy.crs as ccrs\nimport cartopy.feature as cf\n\nfrom math import floor,ceil\n\n\n# x-positions of gridlines (need to specify when over 180 deg)\nxlocs = [100,110, 120, 130, 140, 150, 160, 170, 179.99999, -170, -160, -150, -140, -130, -120, -110, -100]\n\n# central longitude for projection\nclon = 180\n\n# mask values below \"numerical zero\"\nalmost_zero = 1e-16\n</pre> import numpy as np import pandas as pd  import xarray as xr  import matplotlib.pyplot as plt import matplotlib as mpl  import cartopy.crs as ccrs import cartopy.feature as cf  from math import floor,ceil   # x-positions of gridlines (need to specify when over 180 deg) xlocs = [100,110, 120, 130, 140, 150, 160, 170, 179.99999, -170, -160, -150, -140, -130, -120, -110, -100]  # central longitude for projection clon = 180  # mask values below \"numerical zero\" almost_zero = 1e-16  In\u00a0[3]: Copied! <pre>thresholds = np.array([0.2,2,5,10])\nprint(f'concentration thresholds (mg/m3)= {thresholds}')\n\n# colors per threshold\ncolors_rgb= [\n    [160,210,255], # blue\n    [255,153,0], # orange\n    [255,40,0], # red\n    [170,0,170], # purple\n]\n\n# colormap\ncmap = mpl.colors.ListedColormap(np.array(colors_rgb)/255)\ncmap \n</pre>  thresholds = np.array([0.2,2,5,10]) print(f'concentration thresholds (mg/m3)= {thresholds}')  # colors per threshold colors_rgb= [     [160,210,255], # blue     [255,153,0], # orange     [255,40,0], # red     [170,0,170], # purple ]  # colormap cmap = mpl.colors.ListedColormap(np.array(colors_rgb)/255) cmap  <pre>concentration thresholds (mg/m3)= [ 0.2  2.   5.  10. ]\n</pre> Out[3]: from_list  underbad over  In\u00a0[4]: Copied! <pre># without the `extend=max` option, the colorbar will not show the color for the pre-to-last value (red)\n\nnorm = mpl.colors.BoundaryNorm(thresholds,cmap.N, extend='max')\n\nfig, ax = plt.subplots(figsize=(6, 1), layout='constrained')\nfig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap), \n             cax=ax, orientation='horizontal', label='QVA (mg/m3)')#, boundaries=thresholds, ticks=thresholds)\n</pre> # without the `extend=max` option, the colorbar will not show the color for the pre-to-last value (red)  norm = mpl.colors.BoundaryNorm(thresholds,cmap.N, extend='max')  fig, ax = plt.subplots(figsize=(6, 1), layout='constrained') fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap),               cax=ax, orientation='horizontal', label='QVA (mg/m3)')#, boundaries=thresholds, ticks=thresholds)  Out[4]: <pre>&lt;matplotlib.colorbar.Colorbar at 0x7f2d33566b80&gt;</pre> In\u00a0[5]: Copied! <pre>ds = xr.open_dataset('qva_det_Ruapehu_202501081200.nc')\nds\n</pre> ds = xr.open_dataset('qva_det_Ruapehu_202501081200.nc') ds Out[5]: <pre>&lt;xarray.Dataset&gt; Size: 183MB\nDimensions:        (latitude: 361, longitude: 441, levels: 12, time: 24)\nCoordinates:\n  * latitude       (latitude) float32 1kB -84.28 -84.03 -83.78 ... 5.47 5.72\n  * longitude      (longitude) float32 2kB 120.6 120.8 121.1 ... 230.3 230.6\n  * levels         (levels) float64 96B 5e+03 1e+04 1.5e+04 ... 5.5e+04 6e+04\n  * time           (time) datetime64[ns] 192B 2025-01-08T13:00:00 ... 2025-01...\nData variables:\n    concentration  (time, levels, latitude, longitude) float32 183MB ...\nAttributes:\n    title:                            HYSPLIT Model Concentration Output\n    Conventions:                      CF-1.5\n    volcano_name:                     Ruapehu\n    eruption_lon_degrees:             175.57\n    eruption_lat_degrees:             -39.28\n    eruption_vent_meters_msl:         2797.0\n    eruption_height_meters_msl:       12500.0\n    eruption_mass_eruption_rate_kgs:  87500.0\n    eruption_start_time:              2025-01-08T12:00:00\n    eruption_duration_s:              3600.0</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>latitude: 361</li><li>longitude: 441</li><li>levels: 12</li><li>time: 24</li></ul></li><li>Coordinates: (4)<ul><li>latitude(latitude)float32-84.28 -84.03 -83.78 ... 5.47 5.72long_name :latitude degrees north from the equatorunits :degrees_northpoint_spacing :even<pre>array([-84.28    , -84.03    , -83.78    , ...,   5.220001,   5.470001,\n         5.720001], dtype=float32)</pre></li><li>longitude(longitude)float32120.6 120.8 121.1 ... 230.3 230.6long_name :longitude degrees east from the greenwich meridianunits :degrees_eastpoint_spacing :even<pre>array([120.57001, 120.82001, 121.07001, ..., 230.07   , 230.32   , 230.57   ],\n      dtype=float32)</pre></li><li>levels(levels)float645e+03 1e+04 ... 5.5e+04 6e+04long_name :Top of flight level layerunits :feetaxis :Zpositive :up<pre>array([ 5000., 10000., 15000., 20000., 25000., 30000., 35000., 40000., 45000.,\n       50000., 55000., 60000.])</pre></li><li>time(time)datetime64[ns]2025-01-08T13:00:00 ... 2025-01-...axis :Tlong_name :time<pre>array(['2025-01-08T13:00:00.000000000', '2025-01-08T14:00:00.000000000',\n       '2025-01-08T15:00:00.000000000', '2025-01-08T16:00:00.000000000',\n       '2025-01-08T17:00:00.000000000', '2025-01-08T18:00:00.000000000',\n       '2025-01-08T19:00:00.000000000', '2025-01-08T20:00:00.000000000',\n       '2025-01-08T21:00:00.000000000', '2025-01-08T22:00:00.000000000',\n       '2025-01-08T23:00:00.000000000', '2025-01-09T00:00:00.000000000',\n       '2025-01-09T01:00:00.000000000', '2025-01-09T02:00:00.000000000',\n       '2025-01-09T03:00:00.000000000', '2025-01-09T04:00:00.000000000',\n       '2025-01-09T05:00:00.000000000', '2025-01-09T06:00:00.000000000',\n       '2025-01-09T07:00:00.000000000', '2025-01-09T08:00:00.000000000',\n       '2025-01-09T09:00:00.000000000', '2025-01-09T10:00:00.000000000',\n       '2025-01-09T11:00:00.000000000', '2025-01-09T12:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (1)<ul><li>concentration(time, levels, latitude, longitude)float32...long_name :Quantitative volcanic ash concentration from deterministic forecastunits :mg/m3<pre>[45849888 values with dtype=float32]</pre></li></ul></li><li>Indexes: (4)<ul><li>latitudePandasIndex<pre>PandasIndex(Index([-84.27999877929688, -84.02999877929688, -83.77999877929688,\n       -83.52999877929688, -83.27999877929688, -83.02999877929688,\n       -82.77999877929688, -82.52999877929688, -82.27999877929688,\n       -82.02999877929688,\n       ...\n        3.470001220703125,  3.720001220703125,  3.970001220703125,\n        4.220001220703125,  4.470001220703125,  4.720001220703125,\n        4.970001220703125,  5.220001220703125,  5.470001220703125,\n        5.720001220703125],\n      dtype='float32', name='latitude', length=361))</pre></li><li>longitudePandasIndex<pre>PandasIndex(Index([120.57000732421875, 120.82000732421875, 121.07000732421875,\n       121.32000732421875, 121.57000732421875, 121.82000732421875,\n       122.07000732421875, 122.32000732421875, 122.57000732421875,\n       122.82000732421875,\n       ...\n       228.32000732421875, 228.57000732421875, 228.82000732421875,\n       229.07000732421875, 229.32000732421875, 229.57000732421875,\n       229.82000732421875, 230.07000732421875, 230.32000732421875,\n       230.57000732421875],\n      dtype='float32', name='longitude', length=441))</pre></li><li>levelsPandasIndex<pre>PandasIndex(Index([ 5000.0, 10000.0, 15000.0, 20000.0, 25000.0, 30000.0, 35000.0, 40000.0,\n       45000.0, 50000.0, 55000.0, 60000.0],\n      dtype='float64', name='levels'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2025-01-08 13:00:00', '2025-01-08 14:00:00',\n               '2025-01-08 15:00:00', '2025-01-08 16:00:00',\n               '2025-01-08 17:00:00', '2025-01-08 18:00:00',\n               '2025-01-08 19:00:00', '2025-01-08 20:00:00',\n               '2025-01-08 21:00:00', '2025-01-08 22:00:00',\n               '2025-01-08 23:00:00', '2025-01-09 00:00:00',\n               '2025-01-09 01:00:00', '2025-01-09 02:00:00',\n               '2025-01-09 03:00:00', '2025-01-09 04:00:00',\n               '2025-01-09 05:00:00', '2025-01-09 06:00:00',\n               '2025-01-09 07:00:00', '2025-01-09 08:00:00',\n               '2025-01-09 09:00:00', '2025-01-09 10:00:00',\n               '2025-01-09 11:00:00', '2025-01-09 12:00:00'],\n              dtype='datetime64[ns]', name='time', freq=None))</pre></li></ul></li><li>Attributes: (10)title :HYSPLIT Model Concentration OutputConventions :CF-1.5volcano_name :Ruapehueruption_lon_degrees :175.57eruption_lat_degrees :-39.28eruption_vent_meters_msl :2797.0eruption_height_meters_msl :12500.0eruption_mass_eruption_rate_kgs :87500.0eruption_start_time :2025-01-08T12:00:00eruption_duration_s :3600.0</li></ul> In\u00a0[6]: Copied! <pre># determine full extent of the plume at all levels and times\nda = ds['concentration']\nda_m = da.where(da &gt; almost_zero, drop=True)\nprint(f'shape before mask = {da.shape}')\nprint(f'shape after mask  = {da_m.shape}')\n\nbnd = [floor(da_m.longitude.values.min()), ceil(da_m.longitude.values.max()), \n       floor(da_m.latitude.values.min()), ceil(da_m.latitude.values.max())]\nprint(f'full extent of plume = {bnd}')\n</pre> # determine full extent of the plume at all levels and times da = ds['concentration'] da_m = da.where(da &gt; almost_zero, drop=True) print(f'shape before mask = {da.shape}') print(f'shape after mask  = {da_m.shape}')  bnd = [floor(da_m.longitude.values.min()), ceil(da_m.longitude.values.max()),         floor(da_m.latitude.values.min()), ceil(da_m.latitude.values.max())] print(f'full extent of plume = {bnd}') <pre>shape before mask = (24, 12, 361, 441)\nshape after mask  = (24, 9, 44, 128)\nfull extent of plume = [174, 207, -40, -29]\n</pre> In\u00a0[7]: Copied! <pre># determine max concentration at each level to help us plot interesting stuff\nds['concentration'].max(dim=('longitude', 'latitude')).plot(y='levels', x='time')\nplt.title('Max concentration [mg/m3] at each level')\n</pre> # determine max concentration at each level to help us plot interesting stuff ds['concentration'].max(dim=('longitude', 'latitude')).plot(y='levels', x='time') plt.title('Max concentration [mg/m3] at each level') Out[7]: <pre>Text(0.5, 1.0, 'Max concentration [mg/m3] at each level')</pre> <p>Choose time and level to plot</p> In\u00a0[15]: Copied! <pre># time index\nit = 2\n\n# level index of top of the layer\nilev  = 7\n\nprint(ds.time[it].values)\nprint(f'FL{ds.levels[ilev].values/100:.0f}')\n</pre> # time index it = 2  # level index of top of the layer ilev  = 7  print(ds.time[it].values) print(f'FL{ds.levels[ilev].values/100:.0f}')  <pre>2025-01-08T15:00:00.000000000\nFL400\n</pre> <p>Prepare plot title</p> In\u00a0[16]: Copied! <pre>volcano_name = ds.attrs['volcano_name']\nolon = ds.attrs['eruption_lon_degrees']\nolat = ds.attrs['eruption_lat_degrees']\nh_vent = ds.attrs['eruption_vent_meters_msl']\nh_top = ds.attrs['eruption_height_meters_msl']\nmer = ds.attrs['eruption_mass_eruption_rate_kgs']\ndur = ds.attrs['eruption_duration_s']\n\n\ntime = pd.to_datetime(ds.time[it].values)\neruption_start_time = pd.to_datetime(ds.attrs['eruption_start_time'])\nlead_time = (time - eruption_start_time).total_seconds()/3600.\n\nlevel = ds.levels[ilev].values\nlevel_below = ds.levels[ilev-1].values if ilev &gt; 0 else 0\n\nlevel = (level/100).astype(int)\nlevel_below = (level_below/100).astype(int)\n\ntit_str1 = f'{volcano_name} ({olon:.4f} E, {olat:.4f} N, {h_vent:.1f} m asl)' \ntit_str2 = f'H = {h_top/1000.:.1f} km asl; MER = {mer:.1e} kg/s, D = {dur/3600.:.0f} h'\ntit_str3 = f'Valid at {time} (+{lead_time:.0f} h after eruption) for FL{level_below}-FL{level}'\n\ntit_str = f'{tit_str1}\\n{tit_str2}\\n{tit_str3}'\nprint(tit_str)\n</pre> volcano_name = ds.attrs['volcano_name'] olon = ds.attrs['eruption_lon_degrees'] olat = ds.attrs['eruption_lat_degrees'] h_vent = ds.attrs['eruption_vent_meters_msl'] h_top = ds.attrs['eruption_height_meters_msl'] mer = ds.attrs['eruption_mass_eruption_rate_kgs'] dur = ds.attrs['eruption_duration_s']   time = pd.to_datetime(ds.time[it].values) eruption_start_time = pd.to_datetime(ds.attrs['eruption_start_time']) lead_time = (time - eruption_start_time).total_seconds()/3600.  level = ds.levels[ilev].values level_below = ds.levels[ilev-1].values if ilev &gt; 0 else 0  level = (level/100).astype(int) level_below = (level_below/100).astype(int)  tit_str1 = f'{volcano_name} ({olon:.4f} E, {olat:.4f} N, {h_vent:.1f} m asl)'  tit_str2 = f'H = {h_top/1000.:.1f} km asl; MER = {mer:.1e} kg/s, D = {dur/3600.:.0f} h' tit_str3 = f'Valid at {time} (+{lead_time:.0f} h after eruption) for FL{level_below}-FL{level}'  tit_str = f'{tit_str1}\\n{tit_str2}\\n{tit_str3}' print(tit_str)  <pre>Ruapehu (175.5700 E, -39.2800 N, 2797.0 m asl)\nH = 12.5 km asl; MER = 8.8e+04 kg/s, D = 1 h\nValid at 2025-01-08 15:00:00 (+3 h after eruption) for FL350-FL400\n</pre> <p>Plot</p> In\u00a0[20]: Copied! <pre>fig, ax = plt.subplots(1, 1, figsize=(12,5), subplot_kw={\"projection\": ccrs.PlateCarree(clon)})\n\nda = ds['concentration'].isel(time=it, levels=ilev)\n\n# need to mask to lower thredshold so that the lower limit of colorbar is correct (otherwise C &lt; 0.2 will also be blue)\nda_m = da.where(da &gt;= thresholds[0])\n\n# needs extend='max' so that it always plots the colorbar corretly, even if there little ash present (C &lt; 10)\nda_m.plot(ax=ax, norm=norm, cmap=cmap, transform=ccrs.PlateCarree(), extend='max')\n\n# add volcano location\nax.plot(olon, olat, marker='^' , color='k', transform=ccrs.PlateCarree())\n\n# zoom in to see the data\nax.set_extent(bnd)\n# ax.set_extent([175, 180, -40, -35])\n\n# add decorations \n# ax.add_feature(cf.OCEAN)\nax.add_feature(cf.COASTLINE)\nax.add_feature(cf.BORDERS, lw=0.5)\nax.add_feature(cf.LAND, edgecolor='black', facecolor='wheat', linewidth=0.5, alpha=0.5)\nax.add_feature(cf.LAKES, edgecolor='black', facecolor=cf.COLORS['water']) #'none')\nif clon == 180:\n    gl = ax.gridlines(xlocs=xlocs, draw_labels=True, ls=':', color='gray')\nelse:\n    gl = ax.gridlines(draw_labels=True, ls=':', color='gray')\n\ngl.top_labels = False\ngl.right_labels = False\n\nax.set_title(tit_str)\nfig.tight_layout()\n</pre> fig, ax = plt.subplots(1, 1, figsize=(12,5), subplot_kw={\"projection\": ccrs.PlateCarree(clon)})  da = ds['concentration'].isel(time=it, levels=ilev)  # need to mask to lower thredshold so that the lower limit of colorbar is correct (otherwise C &lt; 0.2 will also be blue) da_m = da.where(da &gt;= thresholds[0])  # needs extend='max' so that it always plots the colorbar corretly, even if there little ash present (C &lt; 10) da_m.plot(ax=ax, norm=norm, cmap=cmap, transform=ccrs.PlateCarree(), extend='max')  # add volcano location ax.plot(olon, olat, marker='^' , color='k', transform=ccrs.PlateCarree())  # zoom in to see the data ax.set_extent(bnd) # ax.set_extent([175, 180, -40, -35])  # add decorations  # ax.add_feature(cf.OCEAN) ax.add_feature(cf.COASTLINE) ax.add_feature(cf.BORDERS, lw=0.5) ax.add_feature(cf.LAND, edgecolor='black', facecolor='wheat', linewidth=0.5, alpha=0.5) ax.add_feature(cf.LAKES, edgecolor='black', facecolor=cf.COLORS['water']) #'none') if clon == 180:     gl = ax.gridlines(xlocs=xlocs, draw_labels=True, ls=':', color='gray') else:     gl = ax.gridlines(draw_labels=True, ls=':', color='gray')  gl.top_labels = False gl.right_labels = False  ax.set_title(tit_str) fig.tight_layout()  In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"qva/plot_qva_det/#plot-qva-deterministic","title":"Plot QVA Deterministic\u00b6","text":"<p>Plots a deterministic Quantitative Volcanic Ash Concentration forecast with the agreed colors per threshold:</p> Threshold band (mg/m3) RGB Color name (approx) [0.2 - 2[ [160,210,255] blue [2 - 5[ [255,153,0] orange [5 - 10[ [255,40,0] red [10 - Inf[ [170,0,170] purple <p>Intervals are lower-bound inclusive, upper-bound exclusive.</p> <p>The netcdf file used in this example (qva_det_Ruapehu_202501081200.nc), as well as this notebook are is available in https://github.com/rosatrancoso/notebook-share/blob/master/docs/qva/.</p>"},{"location":"qva/plot_qva_det/#colormap-settings","title":"Colormap settings\u00b6","text":""},{"location":"qva/plot_qva_det/#read-input-netcdf-file","title":"Read input netcdf file\u00b6","text":""},{"location":"qva/plot_qva_det/#get-full-extent-of-the-plume-at-all-levels-and-times","title":"Get full extent of the plume at all levels and times\u00b6","text":"<p>This helps to have the same zoom extent in all plots that fits the data.</p>"},{"location":"qva/plot_qva_det/#get-max-concentration-at-each-level","title":"Get max concentration at each level\u00b6","text":"<p>merely indicative to know where the ash is and plot relevant levels</p>"},{"location":"qva/plot_qva_det/#plot","title":"Plot\u00b6","text":""},{"location":"qva/plot_qva_prob/","title":"Plot QVA Probabilistic","text":"In\u00a0[1]: Copied! <pre># Contents of the netcdf file\n! ncdump -h qva_prob_Ruapehu_202501081200.nc\n</pre> # Contents of the netcdf file ! ncdump -h qva_prob_Ruapehu_202501081200.nc <pre>netcdf qva_prob_Ruapehu_202501081200 {\ndimensions:\n\ttime = UNLIMITED ; // (24 currently)\n\tlatitude = 361 ;\n\tlongitude = 441 ;\n\tlevels = 12 ;\n\tthresholds = 4 ;\nvariables:\n\tfloat latitude(latitude) ;\n\t\tlatitude:_FillValue = NaNf ;\n\t\tlatitude:long_name = \"latitude degrees north from the equator\" ;\n\t\tlatitude:units = \"degrees_north\" ;\n\t\tlatitude:point_spacing = \"even\" ;\n\tfloat longitude(longitude) ;\n\t\tlongitude:_FillValue = NaNf ;\n\t\tlongitude:long_name = \"longitude degrees east from the greenwich meridian\" ;\n\t\tlongitude:units = \"degrees_east\" ;\n\t\tlongitude:point_spacing = \"even\" ;\n\tdouble levels(levels) ;\n\t\tlevels:_FillValue = NaN ;\n\t\tlevels:long_name = \"Top of flight level layer\" ;\n\t\tlevels:units = \"feet\" ;\n\t\tlevels:axis = \"Z\" ;\n\t\tlevels:positive = \"up\" ;\n\tint64 time(time) ;\n\t\ttime:axis = \"T\" ;\n\t\ttime:long_name = \"time\" ;\n\t\ttime:units = \"hours since 2025-01-08T13:00:00\" ;\n\t\ttime:calendar = \"proleptic_gregorian\" ;\n\tdouble thresholds(thresholds) ;\n\t\tthresholds:_FillValue = NaN ;\n\tfloat frequency_of_excedance(thresholds, time, levels, latitude, longitude) ;\n\t\tfrequency_of_excedance:_FillValue = NaNf ;\n\t\tfrequency_of_excedance:long_name = \"Frequency of excedance based on 30 members of GEFS\" ;\n\t\tfrequency_of_excedance:units = \"fraction\" ;\n\t\tfrequency_of_excedance:thresholds = 0.2, 2., 5., 10. ;\n\n// global attributes:\n\t\t:title = \"HYSPLIT Model Concentration Output\" ;\n\t\t:Conventions = \"CF-1.5\" ;\n\t\t:volcano_name = \"Ruapehu\" ;\n\t\t:eruption_lon_degrees = 175.57f ;\n\t\t:eruption_lat_degrees = -39.28f ;\n\t\t:eruption_vent_meters_msl = 2797.f ;\n\t\t:eruption_height_meters_msl = 12500.f ;\n\t\t:eruption_mass_eruption_rate_kgs = 87500. ;\n\t\t:eruption_start_time = \"2025-01-08T12:00:00\" ;\n\t\t:eruption_duration_s = 3600. ;\n}\n</pre> In\u00a0[2]: Copied! <pre>import numpy as np\nimport pandas as pd \nimport xarray as xr\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\nimport cartopy.crs as ccrs\nimport cartopy.feature as cf\n\nfrom math import floor,ceil\n\n# x-positions of gridlines (need to specify when over 180 deg)\nxlocs = [100,110, 120, 130, 140, 150, 160, 170, 179.99999, -170, -160, -150, -140, -130, -120, -110, -100]\n\n# central longitude for projection\nclon = 180\n\n# mask values below \"numerical zero\"\nalmost_zero = 1e-16\n</pre> import numpy as np import pandas as pd  import xarray as xr  import matplotlib.pyplot as plt import matplotlib as mpl  import cartopy.crs as ccrs import cartopy.feature as cf  from math import floor,ceil  # x-positions of gridlines (need to specify when over 180 deg) xlocs = [100,110, 120, 130, 140, 150, 160, 170, 179.99999, -170, -160, -150, -140, -130, -120, -110, -100]  # central longitude for projection clon = 180  # mask values below \"numerical zero\" almost_zero = 1e-16 In\u00a0[3]: Copied! <pre>thresholds = np.array([0.2,2,5,10])\nprint(f'concentration thresholds (mg/m3)= {thresholds}')\n\n# Colormaps per threshold band\ncolormaps = {\n    0.2: 'Blues',\n    2: 'YlOrBr',\n    5: 'Reds',\n    10: 'RdPu',\n}\n\n# contour levels for colorbar\ncontour_levels = [0.01,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n\nnorm = mpl.colors.BoundaryNorm(boundaries=contour_levels, ncolors=256)\n\nfor i in range(len(thresholds)):\n    print(i, thresholds[i], colormaps[thresholds[i]])\n    fig, ax = plt.subplots(figsize=(6, 1), layout='constrained')\n    fig.colorbar(mpl.cm.ScalarMappable(cmap=colormaps[thresholds[i]], norm=norm),\n                cax=ax, orientation='horizontal', label=colormaps[thresholds[i]])\n</pre> thresholds = np.array([0.2,2,5,10]) print(f'concentration thresholds (mg/m3)= {thresholds}')  # Colormaps per threshold band colormaps = {     0.2: 'Blues',     2: 'YlOrBr',     5: 'Reds',     10: 'RdPu', }  # contour levels for colorbar contour_levels = [0.01,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]  norm = mpl.colors.BoundaryNorm(boundaries=contour_levels, ncolors=256)  for i in range(len(thresholds)):     print(i, thresholds[i], colormaps[thresholds[i]])     fig, ax = plt.subplots(figsize=(6, 1), layout='constrained')     fig.colorbar(mpl.cm.ScalarMappable(cmap=colormaps[thresholds[i]], norm=norm),                 cax=ax, orientation='horizontal', label=colormaps[thresholds[i]])    <pre>concentration thresholds (mg/m3)= [ 0.2  2.   5.  10. ]\n0 0.2 Blues\n1 2.0 YlOrBr\n2 5.0 Reds\n3 10.0 RdPu\n</pre> In\u00a0[4]: Copied! <pre>ds = xr.open_dataset('qva_prob_Ruapehu_202501081200.nc')\nds\n</pre> ds = xr.open_dataset('qva_prob_Ruapehu_202501081200.nc') ds Out[4]: <pre>&lt;xarray.Dataset&gt; Size: 734MB\nDimensions:                 (latitude: 361, longitude: 441, levels: 12,\n                             time: 24, thresholds: 4)\nCoordinates:\n  * latitude                (latitude) float32 1kB -84.28 -84.03 ... 5.47 5.72\n  * longitude               (longitude) float32 2kB 120.6 120.8 ... 230.3 230.6\n  * levels                  (levels) float64 96B 5e+03 1e+04 ... 5.5e+04 6e+04\n  * time                    (time) datetime64[ns] 192B 2025-01-08T13:00:00 .....\n  * thresholds              (thresholds) float64 32B 0.2 2.0 5.0 10.0\nData variables:\n    frequency_of_excedance  (thresholds, time, levels, latitude, longitude) float32 734MB ...\nAttributes:\n    title:                            HYSPLIT Model Concentration Output\n    Conventions:                      CF-1.5\n    volcano_name:                     Ruapehu\n    eruption_lon_degrees:             175.57\n    eruption_lat_degrees:             -39.28\n    eruption_vent_meters_msl:         2797.0\n    eruption_height_meters_msl:       12500.0\n    eruption_mass_eruption_rate_kgs:  87500.0\n    eruption_start_time:              2025-01-08T12:00:00\n    eruption_duration_s:              3600.0</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>latitude: 361</li><li>longitude: 441</li><li>levels: 12</li><li>time: 24</li><li>thresholds: 4</li></ul></li><li>Coordinates: (5)<ul><li>latitude(latitude)float32-84.28 -84.03 -83.78 ... 5.47 5.72long_name :latitude degrees north from the equatorunits :degrees_northpoint_spacing :even<pre>array([-84.28    , -84.03    , -83.78    , ...,   5.220001,   5.470001,\n         5.720001], dtype=float32)</pre></li><li>longitude(longitude)float32120.6 120.8 121.1 ... 230.3 230.6long_name :longitude degrees east from the greenwich meridianunits :degrees_eastpoint_spacing :even<pre>array([120.57001, 120.82001, 121.07001, ..., 230.07   , 230.32   , 230.57   ],\n      dtype=float32)</pre></li><li>levels(levels)float645e+03 1e+04 ... 5.5e+04 6e+04long_name :Top of flight level layerunits :feetaxis :Zpositive :up<pre>array([ 5000., 10000., 15000., 20000., 25000., 30000., 35000., 40000., 45000.,\n       50000., 55000., 60000.])</pre></li><li>time(time)datetime64[ns]2025-01-08T13:00:00 ... 2025-01-...axis :Tlong_name :time<pre>array(['2025-01-08T13:00:00.000000000', '2025-01-08T14:00:00.000000000',\n       '2025-01-08T15:00:00.000000000', '2025-01-08T16:00:00.000000000',\n       '2025-01-08T17:00:00.000000000', '2025-01-08T18:00:00.000000000',\n       '2025-01-08T19:00:00.000000000', '2025-01-08T20:00:00.000000000',\n       '2025-01-08T21:00:00.000000000', '2025-01-08T22:00:00.000000000',\n       '2025-01-08T23:00:00.000000000', '2025-01-09T00:00:00.000000000',\n       '2025-01-09T01:00:00.000000000', '2025-01-09T02:00:00.000000000',\n       '2025-01-09T03:00:00.000000000', '2025-01-09T04:00:00.000000000',\n       '2025-01-09T05:00:00.000000000', '2025-01-09T06:00:00.000000000',\n       '2025-01-09T07:00:00.000000000', '2025-01-09T08:00:00.000000000',\n       '2025-01-09T09:00:00.000000000', '2025-01-09T10:00:00.000000000',\n       '2025-01-09T11:00:00.000000000', '2025-01-09T12:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li><li>thresholds(thresholds)float640.2 2.0 5.0 10.0<pre>array([ 0.2,  2. ,  5. , 10. ])</pre></li></ul></li><li>Data variables: (1)<ul><li>frequency_of_excedance(thresholds, time, levels, latitude, longitude)float32...long_name :Frequency of excedance based on 30 members of GEFSunits :fractionthresholds :[ 0.2  2.   5.  10. ]<pre>[183399552 values with dtype=float32]</pre></li></ul></li><li>Indexes: (5)<ul><li>latitudePandasIndex<pre>PandasIndex(Index([-84.27999877929688, -84.02999877929688, -83.77999877929688,\n       -83.52999877929688, -83.27999877929688, -83.02999877929688,\n       -82.77999877929688, -82.52999877929688, -82.27999877929688,\n       -82.02999877929688,\n       ...\n        3.470001220703125,  3.720001220703125,  3.970001220703125,\n        4.220001220703125,  4.470001220703125,  4.720001220703125,\n        4.970001220703125,  5.220001220703125,  5.470001220703125,\n        5.720001220703125],\n      dtype='float32', name='latitude', length=361))</pre></li><li>longitudePandasIndex<pre>PandasIndex(Index([120.57000732421875, 120.82000732421875, 121.07000732421875,\n       121.32000732421875, 121.57000732421875, 121.82000732421875,\n       122.07000732421875, 122.32000732421875, 122.57000732421875,\n       122.82000732421875,\n       ...\n       228.32000732421875, 228.57000732421875, 228.82000732421875,\n       229.07000732421875, 229.32000732421875, 229.57000732421875,\n       229.82000732421875, 230.07000732421875, 230.32000732421875,\n       230.57000732421875],\n      dtype='float32', name='longitude', length=441))</pre></li><li>levelsPandasIndex<pre>PandasIndex(Index([ 5000.0, 10000.0, 15000.0, 20000.0, 25000.0, 30000.0, 35000.0, 40000.0,\n       45000.0, 50000.0, 55000.0, 60000.0],\n      dtype='float64', name='levels'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2025-01-08 13:00:00', '2025-01-08 14:00:00',\n               '2025-01-08 15:00:00', '2025-01-08 16:00:00',\n               '2025-01-08 17:00:00', '2025-01-08 18:00:00',\n               '2025-01-08 19:00:00', '2025-01-08 20:00:00',\n               '2025-01-08 21:00:00', '2025-01-08 22:00:00',\n               '2025-01-08 23:00:00', '2025-01-09 00:00:00',\n               '2025-01-09 01:00:00', '2025-01-09 02:00:00',\n               '2025-01-09 03:00:00', '2025-01-09 04:00:00',\n               '2025-01-09 05:00:00', '2025-01-09 06:00:00',\n               '2025-01-09 07:00:00', '2025-01-09 08:00:00',\n               '2025-01-09 09:00:00', '2025-01-09 10:00:00',\n               '2025-01-09 11:00:00', '2025-01-09 12:00:00'],\n              dtype='datetime64[ns]', name='time', freq=None))</pre></li><li>thresholdsPandasIndex<pre>PandasIndex(Index([0.2, 2.0, 5.0, 10.0], dtype='float64', name='thresholds'))</pre></li></ul></li><li>Attributes: (10)title :HYSPLIT Model Concentration OutputConventions :CF-1.5volcano_name :Ruapehueruption_lon_degrees :175.57eruption_lat_degrees :-39.28eruption_vent_meters_msl :2797.0eruption_height_meters_msl :12500.0eruption_mass_eruption_rate_kgs :87500.0eruption_start_time :2025-01-08T12:00:00eruption_duration_s :3600.0</li></ul> In\u00a0[5]: Copied! <pre># determine full extent of the plume at all levels and times\nda = ds['frequency_of_excedance']\nda_m = da.where(da &gt; almost_zero, drop=True)\nprint(f'before mask = {da.shape}')\nprint(f'after mask  = {da_m.shape}')\n\nbnd = [floor(da_m.longitude.values.min()), ceil(da_m.longitude.values.max()), \n       floor(da_m.latitude.values.min()), ceil(da_m.latitude.values.max())]\nprint(f'full extent of plume = {bnd}')\n</pre> # determine full extent of the plume at all levels and times da = ds['frequency_of_excedance'] da_m = da.where(da &gt; almost_zero, drop=True) print(f'before mask = {da.shape}') print(f'after mask  = {da_m.shape}')  bnd = [floor(da_m.longitude.values.min()), ceil(da_m.longitude.values.max()),         floor(da_m.latitude.values.min()), ceil(da_m.latitude.values.max())] print(f'full extent of plume = {bnd}') <pre>before mask = (4, 24, 12, 361, 441)\nafter mask  = (4, 24, 12, 42, 124)\nfull extent of plume = [175, 207, -42, -31]\n</pre> <p>Choose time and level to plot</p> In\u00a0[6]: Copied! <pre># time index\nit = 2\n\n# level index of top of the layer\nilev  = 7\n\nprint(ds.time[it].values)\nprint(f'FL{ds.levels[ilev].values/100:.0f}')\n</pre> # time index it = 2  # level index of top of the layer ilev  = 7  print(ds.time[it].values) print(f'FL{ds.levels[ilev].values/100:.0f}')  <pre>2025-01-08T15:00:00.000000000\nFL400\n</pre> <p>Prepare plot title</p> In\u00a0[10]: Copied! <pre>volcano_name = ds.attrs['volcano_name']\nolon = ds.attrs['eruption_lon_degrees']\nolat = ds.attrs['eruption_lat_degrees']\nh_vent = ds.attrs['eruption_vent_meters_msl']\nh_top = ds.attrs['eruption_height_meters_msl']\nmer = ds.attrs['eruption_mass_eruption_rate_kgs']\ndur = ds.attrs['eruption_duration_s']\n\n\ntime = pd.to_datetime(ds.time[it].values)\neruption_start_time = pd.to_datetime(ds.attrs['eruption_start_time'])\nlead_time = (time - eruption_start_time).total_seconds()/3600.\n\nlevel = ds.levels[ilev].values\nlevel_below = ds.levels[ilev-1].values if ilev &gt; 0 else 0\n\nlevel = (level/100).astype(int)\nlevel_below = (level_below/100).astype(int)\n\ntit_str1 = f'{volcano_name} ({olon:.4f} E, {olat:.4f} N, {h_vent:.1f} m asl)' \ntit_str2 = f'H = {h_top/1000.:.1f} km asl; MER = {mer:.1e} kg/s, D = {dur/3600.:.0f} h'\ntit_str3 = f'Valid at {time} (+{lead_time:.0f} h after eruption) for FL{level_below}-FL{level}'\n\ntit_str = f'{tit_str1}\\n{tit_str2}\\n{tit_str3}'\nprint(tit_str)\n</pre> volcano_name = ds.attrs['volcano_name'] olon = ds.attrs['eruption_lon_degrees'] olat = ds.attrs['eruption_lat_degrees'] h_vent = ds.attrs['eruption_vent_meters_msl'] h_top = ds.attrs['eruption_height_meters_msl'] mer = ds.attrs['eruption_mass_eruption_rate_kgs'] dur = ds.attrs['eruption_duration_s']   time = pd.to_datetime(ds.time[it].values) eruption_start_time = pd.to_datetime(ds.attrs['eruption_start_time']) lead_time = (time - eruption_start_time).total_seconds()/3600.  level = ds.levels[ilev].values level_below = ds.levels[ilev-1].values if ilev &gt; 0 else 0  level = (level/100).astype(int) level_below = (level_below/100).astype(int)  tit_str1 = f'{volcano_name} ({olon:.4f} E, {olat:.4f} N, {h_vent:.1f} m asl)'  tit_str2 = f'H = {h_top/1000.:.1f} km asl; MER = {mer:.1e} kg/s, D = {dur/3600.:.0f} h' tit_str3 = f'Valid at {time} (+{lead_time:.0f} h after eruption) for FL{level_below}-FL{level}'  tit_str = f'{tit_str1}\\n{tit_str2}\\n{tit_str3}' print(tit_str) <pre>Ruapehu (175.5700 E, -39.2800 N, 2797.0 m asl)\nH = 12.5 km asl; MER = 8.8e+04 kg/s, D = 1 h\nValid at 2025-01-08 15:00:00 (+3 h after eruption) for FL350-FL400\n</pre> <p>Plots for each threshold</p> In\u00a0[19]: Copied! <pre>fig, axs = plt.subplots(len(thresholds), 1, figsize=(10,12), subplot_kw={\"projection\": ccrs.PlateCarree(clon)})\n\nfor ithreshold in range(len(thresholds)):\n\n    ax = axs.flatten()[ithreshold]\n    \n    da = ds['frequency_of_excedance'].isel(time=it, levels=ilev, thresholds=ithreshold)\n\n    # need to mask to lower countour level so that the lower limit of colorbar is correct (otherwise everything is lower-level color)\n    da_m = da.where(da &gt; contour_levels[0])\n\n    cmap = colormaps[thresholds[ithreshold]]\n    norm = mpl.colors.BoundaryNorm(boundaries=contour_levels, ncolors=256)\n    da_m.plot(ax=ax, norm=norm, cmap=cmap, transform=ccrs.PlateCarree(), cbar_kwargs={'label': \"Frequency [-]\"})\n\n    # add volcano location\n    ax.plot(olon, olat, marker='^' , color='k', transform=ccrs.PlateCarree())\n\n    # zoom in to see the data\n    ax.set_extent(bnd)\n    # ax.set_extent([175, 180, -40, -35])\n\n    # add decorations \n    # ax.add_feature(cf.OCEAN)\n    ax.add_feature(cf.COASTLINE)\n    ax.add_feature(cf.BORDERS, lw=0.5)\n    ax.add_feature(cf.LAND, edgecolor='black', facecolor='wheat', linewidth=0.5, alpha=0.5)\n    ax.add_feature(cf.LAKES, edgecolor='black', facecolor=cf.COLORS['water']) #'none')\n    if clon == 180:\n        gl = ax.gridlines(xlocs=xlocs, draw_labels=True, ls=':', color='gray')\n    else:\n        gl = ax.gridlines(draw_labels=True, ls=':', color='gray')\n\n    gl.top_labels = False\n    gl.right_labels = False\n    ax.set_title(f'Frequency of excedance of {thresholds[ithreshold]} mg/m3')\n\nfig.suptitle(tit_str)#, fontsize='small')\nfig.tight_layout()\n</pre> fig, axs = plt.subplots(len(thresholds), 1, figsize=(10,12), subplot_kw={\"projection\": ccrs.PlateCarree(clon)})  for ithreshold in range(len(thresholds)):      ax = axs.flatten()[ithreshold]          da = ds['frequency_of_excedance'].isel(time=it, levels=ilev, thresholds=ithreshold)      # need to mask to lower countour level so that the lower limit of colorbar is correct (otherwise everything is lower-level color)     da_m = da.where(da &gt; contour_levels[0])      cmap = colormaps[thresholds[ithreshold]]     norm = mpl.colors.BoundaryNorm(boundaries=contour_levels, ncolors=256)     da_m.plot(ax=ax, norm=norm, cmap=cmap, transform=ccrs.PlateCarree(), cbar_kwargs={'label': \"Frequency [-]\"})      # add volcano location     ax.plot(olon, olat, marker='^' , color='k', transform=ccrs.PlateCarree())      # zoom in to see the data     ax.set_extent(bnd)     # ax.set_extent([175, 180, -40, -35])      # add decorations      # ax.add_feature(cf.OCEAN)     ax.add_feature(cf.COASTLINE)     ax.add_feature(cf.BORDERS, lw=0.5)     ax.add_feature(cf.LAND, edgecolor='black', facecolor='wheat', linewidth=0.5, alpha=0.5)     ax.add_feature(cf.LAKES, edgecolor='black', facecolor=cf.COLORS['water']) #'none')     if clon == 180:         gl = ax.gridlines(xlocs=xlocs, draw_labels=True, ls=':', color='gray')     else:         gl = ax.gridlines(draw_labels=True, ls=':', color='gray')      gl.top_labels = False     gl.right_labels = False     ax.set_title(f'Frequency of excedance of {thresholds[ithreshold]} mg/m3')  fig.suptitle(tit_str)#, fontsize='small') fig.tight_layout() In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"qva/plot_qva_prob/#plot-qva-probabilistic","title":"Plot QVA Probabilistic\u00b6","text":"<p>Plots a probabilistic Quantitative Volcanic Ash Concentration forecast with the agreed colormaps per threshold:</p> Threshold band (mg/m3) Colormap [0.2 - 2[ Blues [2 - 5[ YlOrBr [5 - 10[ Reds [10 - Inf[ RbPu <p>Intervals are lower-bound inclusive, upper-bound exclusive.</p> <p>The netcdf file used in this example (qva_prob_Ruapehu_202501081200.nc), as well as this notebook are is available in https://github.com/rosatrancoso/notebook-share/blob/master/docs/qva/.</p>"},{"location":"qva/plot_qva_prob/#colormap-settings","title":"Colormap settings\u00b6","text":""},{"location":"qva/plot_qva_prob/#read-input-file","title":"Read input file\u00b6","text":""},{"location":"qva/plot_qva_prob/#get-full-extent-of-the-plume-at-all-levels-and-times","title":"Get full extent of the plume at all levels and times\u00b6","text":"<p>This helps to have the same zoom extent in all plots that fits the data.</p>"},{"location":"qva/plot_qva_prob/#plot","title":"Plot\u00b6","text":""}]}